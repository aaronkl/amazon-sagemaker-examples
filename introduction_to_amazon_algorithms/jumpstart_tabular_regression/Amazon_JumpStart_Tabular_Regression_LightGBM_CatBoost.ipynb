{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pursuant-strand",
   "metadata": {},
   "source": [
    "# JumpStart: Tabular Regression using LightGBM and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-point",
   "metadata": {},
   "source": [
    "---\n",
    "Welcome to Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)! You can use JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker JumpStart API](https://sagemaker.readthedocs.io/en/stable/doc_utils/jumpstart.html). \n",
    "\n",
    "In this demo notebook, we demonstrate how to use the JumpStart API for tabular data regression using two popular algorithms: [LightGBM](https://lightgbm.readthedocs.io/en/latest/) and [CatBoost](https://catboost.ai/en/docs/). Tabular regression is the task of analyzing the relationship between predictor variables and a response variable in a structured or relational data. \n",
    "\n",
    "In this notebook, we demonstrate two use cases of tabular regression models:\n",
    "\n",
    "* How to train a tabular model on an example dataset to do regression.\n",
    "* How to use the trained tabular model to perform inference, i.e., predicting new samples.\n",
    "\n",
    "Note: This notebook was tested in Amazon SageMaker Studio on ml.t3.medium instance with Python 3 (Data Science) kernel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-sheriff",
   "metadata": {},
   "source": [
    "1. [Set Up](#1.-Set-Up)\n",
    "2. [Train A Tabular Model on ABALONE Dataset](#2.-Train-a-Tabular-Model-on-ABALONE-Dataset)\n",
    "    * [Retrieve Training Artifacts](#2.1.-Retrieve-Training-Artifacts)\n",
    "    * [Set Training Parameters](#2.2.-Set-Training-Parameters)\n",
    "    * [Start Training](#2.3.-Start-Training)\n",
    "    * [Train with Automatic Model Tuning](#2.4.-Train-with-Automatic-Model-Tuning)    \n",
    "3. [Deploy and Run Inference on the Trained Tabular Model](#3.-Deploy-and-Run-Inference-on-the-Trained-Tabular-Model)\n",
    "4. [Evaluate the Prediction Results Returned from the Endpoint](#4.-Evaluate-the-Prediction-Results-Returned-from-the-Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-chance",
   "metadata": {},
   "source": [
    "## 1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-begin",
   "metadata": {},
   "source": [
    "---\n",
    "Before executing the notebook, there are some initial steps required for setup. This notebook requires latest version of sagemaker and ipywidgets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enormous-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-vision 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon-text 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon-tabular 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon-mxnet 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon-features 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "autogluon-extra 0.1.0 requires autogluon.core==0.1.0, which is not installed.\n",
      "sagemakermodelhub 0.19.8 requires pydocstyle==6.1.1, which is not installed.\n",
      "sagemakermodelhub 0.19.8 requires snowballstemmer==2.2.0, which is not installed.\n",
      "sagemakermodelhub 0.19.8 requires types-pytz==2021.3.5, which is not installed.\n",
      "autogluon-vision 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-text 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-text 0.1.0 requires scipy==1.5.4, but you have scipy 1.7.1 which is incompatible.\n",
      "autogluon-tabular 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-tabular 0.1.0 requires scipy==1.5.4, but you have scipy 1.7.1 which is incompatible.\n",
      "autogluon-mxnet 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-features 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-extra 0.1.0 requires numpy==1.19.5, but you have numpy 1.21.2 which is incompatible.\n",
      "autogluon-extra 0.1.0 requires scipy==1.5.4, but you have scipy 1.7.1 which is incompatible.\n",
      "aiobotocore 1.2.2 requires botocore<1.19.53,>=1.19.52, but you have botocore 1.24.1 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires attrs==21.2.0, but you have attrs 20.3.0 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires boto3==1.20.32, but you have boto3 1.21.1 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires botocore==1.23.32, but you have botocore 1.24.1 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires numpy==1.21.5, but you have numpy 1.21.2 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires parameterized==0.8.1, but you have parameterized 0.7.5 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires s3transfer==0.5.0, but you have s3transfer 0.5.1 which is incompatible.\n",
      "sagemakermodelhub 0.19.8 requires sagemaker==2.72.3, but you have sagemaker 2.86.2 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ip (/Users/kleiaaro/virtualenvs/virtual/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-velvet",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "To train and host on Amazon Sagemaker, we need to setup and authenticate the use of AWS services. Here, we use the execution role associated with the current notebook instance as the AWS account role with SageMaker access. It has necessary permissions, including access to your data in S3. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-kansas",
   "metadata": {},
   "source": [
    "## 2. Train a Tabular Model on ABALONE Dataset\n",
    "\n",
    "---\n",
    "\n",
    "In this demonstration, we will train a tabular algorithm on the\n",
    "[ABALONE](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) dataset. \n",
    "The dataset contains examples of eight physical measurements such as length, diameter, and height to predict the age of abalone. \n",
    "Among the eight physical measurements (features), there are one categorical feature and seven numerical features. ABALONE dataset is downloaded from [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html).\n",
    "\n",
    "Below is the screenshot of the first 5 examples in the ABALONE dataset. \n",
    "\n",
    "![test_data_head.jpg](https://jumpstart-cache-prod-us-west-2.s3-us-west-2.amazonaws.com/catboost-metadata/assets/regression_abalone_testset_head.png) \n",
    "\n",
    "If you want to bring your own dataset, below are the instructions on how the training data should be formatted as input to the model.\n",
    "\n",
    "A S3 path should contain two sub-directories 'train/', 'validation/' (optional), and a json-format file named 'categorical_index.json' (optional). Each sub-directory contains a 'data.csv' file (The ABALONE dataset used in this example has been prepared and saved in `training_dataset_s3_path` shown below).\n",
    "* The 'data.csv' files under sub-directory 'train/' and 'validation/' are for training and validation, respectively. The validation data is used to compute a validation score at the end of each boosting iteration. An early stopping is applied when the validation score stops improving. If the validation data is not provided, a 20% of training data is randomly sampled to serve as the validation data. \n",
    "\n",
    "* The first column of the 'data.csv' should have the corresponding target variable. The rest of other columns should have the corresponding predictor variables (features). \n",
    "\n",
    "* If the predictors include categorical feature(s), a json-format file named 'categorical_index.json' should be included in the input directory to indicate the column index(es) of the categorical features. Within the json-format file, it should have a python directory where the key is a string of 'cat_index_list' and the value is a list of unique integer(s). Each integer in the list indicates the column index of categorical features in the 'data.csv'. The range of each integer should be more than 0 (index 0 indicates the target) and less than the total number of columns.   \n",
    "\n",
    "* All the categorical features and the target must be encoded as non-negative integers (```int```) less than ```Int32.MaxValue``` (2147483647). It is best to use a contiguous range of integers started from zero.\n",
    "\n",
    "* Note. The number of json-format files should be no more than 1 in the input directory.  \n",
    "\n",
    "Citations:\n",
    "\n",
    "- Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-nevada",
   "metadata": {},
   "source": [
    "### 2.1. Retrieve Training Artifacts\n",
    "\n",
    "___\n",
    "\n",
    "Here, we retrieve the training docker container, the training algorithm source, and the tabular algorithm. Note that model_version=\"*\" fetches the latest model.\n",
    "\n",
    "For the training algorithm, we have two choices in this demonstration.\n",
    "* [LightGBM](https://lightgbm.readthedocs.io/en/latest/): To use this algorithm, specify `train_model_id` as `lightgbm-regression-model` in the cell below.\n",
    "* [CatBoost](https://catboost.ai/en/docs/): To use this algorithm, specify `train_model_id` as `catboost-regression-model` in the cell below.\n",
    "\n",
    "Note. [XGBoost](https://xgboost.readthedocs.io/en/latest/) (`train_model_id: xgboost-regression-model`) and [Linear Learner](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) (`train_model_id: sklearn-regression-linear`) are the other choices in the tabular regression category. Since they have different input-format requirements, please check a separate notebook `Amazon_JumpStart_Tabular_Regression_XGBoost_LinearLearner.ipynb` for details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exceptional-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# Currently, not all the object detection models in jumpstart support finetuning. Thus, we manually select a model\n",
    "# which supports finetuning.\n",
    "train_model_id, train_model_version, train_scope = \"lightgbm-regression-model\", \"*\", \"training\"\n",
    "# train_model_id, train_model_version, train_scope = \"catboost-regression-model\", \"*\", \"training\"\n",
    "\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-tuner",
   "metadata": {},
   "source": [
    "### 2.2. Set Training Parameters\n",
    "\n",
    "---\n",
    "Now that we are done with all the setup that is needed, we are ready to train our tabular algorithm. To begin, let us create a [``sageMaker.estimator.Estimator``](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) object. This estimator will launch the training job. \n",
    "\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include: (i) Training data path. This is S3 folder in which the input data is stored, (ii) Output path: This the s3 folder in which the training output is stored. (iii) Training instance type: This indicates the type of machine on which to run the training.\n",
    "\n",
    "The second set of parameters are algorithm specific training hyper-parameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "promising-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data is available in this bucket\n",
    "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "training_data_prefix = \"training-datasets/tabular_regress/\"\n",
    "\n",
    "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "output_bucket = sess.default_bucket()\n",
    "output_prefix = \"jumpstart-example-tabular-training\"\n",
    "\n",
    "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-valley",
   "metadata": {},
   "source": [
    "---\n",
    "For algorithm specific hyper-parameters, we start by fetching python dictionary of the training hyper-parameters that the algorithm accepts with their default values. This can then be overridden to custom values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "photographic-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': '500', 'early_stopping_rounds': '5', 'learning_rate': '0.03', 'depth': '6', 'l2_leaf_reg': '3', 'random_strength': '1.0', 'num_boost_round': '500'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\n",
    "    \"num_boost_round\"\n",
    "] = \"500\"  # The same hyperparameter is named as \"iterations\" for CatBoost\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-cursor",
   "metadata": {},
   "source": [
    "### 2.3. Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-blogger",
   "metadata": {},
   "source": [
    "---\n",
    "We start by creating the estimator object with all the required assets and then launch the training job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acoustic-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-example-{train_model_id}-training\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tabular_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Training job by passing s3 path of the training data\n",
    "tabular_estimator.fit({\"training\": training_dataset_s3_path}, logs=True, job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c6f3d",
   "metadata": {},
   "source": [
    "### 2.4. Train with Automatic Model Tuning\n",
    "\n",
    "\n",
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. We will use a HyperparameterTuner object to interact with Amazon SageMaker hyperparameter tuning APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9445339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, HyperparameterTuner\n",
    "\n",
    "\n",
    "if train_model_version == 'lightgbm-regression-model'\n",
    "    hyperparameter_ranges = {\n",
    "        \"learning_rate\": ContinuousParameter(1e-4, 1, scaling_type=\"Logarithmic\"),\n",
    "        \"num_boost_round\": IntegerParameter(2, 30),\n",
    "        \"early_stopping_rounds\": IntegerParameter(2, 30),\n",
    "        \"num_leaves\": IntegerParameter(10, 50),\n",
    "        \"feature_fraction\": ContinuousParameter(0, 1),\n",
    "        \"bagging_fraction\": ContinuousParameter(0, 1),\n",
    "        \"bagging_freq\": IntegerParameter(1, 10),\n",
    "        \"max_depth\": IntegerParameter(5, 30),\n",
    "        \"min_data_in_leaf\": IntegerParameter(5, 50),\n",
    "    }\n",
    "\n",
    "if train_model_version == \"catboost-regression-model\",\n",
    "    hyperparameter_ranges = {\n",
    "        \"learning_rate\": ContinuousParameter(0.00001, 0.1, scaling_type=\"Logarithmic\"),\n",
    "        \"iterations\": IntegerParameter(50, 1000),\n",
    "        \"early_stopping_rounds\": IntegerParameter(1, 10),\n",
    "        \"depth\": IntegerParameter(1, 10),\n",
    "        \"l2_leaf_reg\": IntegerParameter(1, 10),\n",
    "        \"random_strength\": ContinuousParameter(0.01, 10, scaling_type='Logarithmic')\n",
    "    }\n",
    "\n",
    "metric_definitions = {\"metrics\": [{\"Name\": \"rmse\", \"Regex\": \"rmse: ([0-9\\\\.]+)\"}]}\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    tabular_estimator,\n",
    "    metric_definitions[\"metrics\"][0][\"Name\"],\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions[\"metrics\"],\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=metric_definitions.get(\"type\", \"Minimize\"),\n",
    "    base_tuning_job_name=training_job_name,\n",
    ")\n",
    "\n",
    "\n",
    "tuner.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-kidney",
   "metadata": {},
   "source": [
    "## 3. Deploy and Run Inference on the Trained Tabular Model\n",
    "\n",
    "---\n",
    "\n",
    "In this section, you learn how to query an existing endpoint and make predictions of the examples you input. For each example, the model will output a numerical value to estimate the corresponding target value.\n",
    "\n",
    "We start by retrieving the jumpstart artifacts and deploy the `tabular_estimator` that we trained.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "entertaining-variation",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Best training job not available for tuning job: jumpstart-example-ca-220420-1321",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/virtualenvs/virtual/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuning_job_describe_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BestTrainingJob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BestTrainingJob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ld/vzcn3j2d7yg493b1c6m0ypprdqgxkm/T/ipykernel_16886/3277798484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mimage_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy_image_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msource_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy_source_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m )\n",
      "\u001b[0;32m~/virtualenvs/virtual/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, wait, model_name, kms_key, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mobtain\u001b[0m \u001b[0minferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \"\"\"\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mbest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0mbest_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/virtual/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    859\u001b[0m             raise Exception(\n\u001b[1;32m    860\u001b[0m                 \"Best training job not available for tuning job: {}\".format(\n\u001b[0;32m--> 861\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 )\n\u001b[1;32m    863\u001b[0m             )\n",
      "\u001b[0;31mException\u001b[0m: Best training job not available for tuning job: jumpstart-example-ca-220420-1321"
     ]
    }
   ],
   "source": [
    "inference_instance_type = \"ml.m5.large\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{train_model_id}-\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-sociology",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we download a hold-out ABALONE test data from the S3 bucket for inference.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "identified-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpstart_assets_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "test_data_prefix = \"training-datasets/tabular_regress/test\"\n",
    "test_data_file_name = \"data.csv\"\n",
    "\n",
    "boto3.client(\"s3\").download_file(\n",
    "    jumpstart_assets_bucket, f\"{test_data_prefix}/{test_data_file_name}\", test_data_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-clinton",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we read the ABALONE test data into pandas data frame, prepare the ground truth target and predicting features to send into the endpoint. \n",
    "\n",
    "Below is the screenshot of the first 5 examples in the ABALONE test set. All of the test examples with features \n",
    "from ```Feature_1``` to ```Feature_8``` are sent into the deployed model \n",
    "to get model predictions, to estimate the ground truth ```Target``` column. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "interstate-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe test dataset contains 626 examples and 9 columns.\u001b[0m\n",
      "\n",
      "\u001b[1mThe first 5 observations of the test data: \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0      11          1      0.585      0.455      0.150     0.9870     0.4355   \n",
       "1       5          3      0.325      0.245      0.075     0.1495     0.0605   \n",
       "2       9          3      0.580      0.420      0.140     0.7010     0.3285   \n",
       "3      12          2      0.480      0.380      0.145     0.5900     0.2320   \n",
       "4      11          2      0.440      0.355      0.115     0.4150     0.1585   \n",
       "\n",
       "   Feature_7  Feature_8  \n",
       "0     0.2075     0.3100  \n",
       "1     0.0330     0.0450  \n",
       "2     0.1020     0.2255  \n",
       "3     0.1410     0.2300  \n",
       "4     0.0925     0.1310  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the data\n",
    "test_data = pd.read_csv(test_data_file_name, header=None)\n",
    "test_data.columns = [\"Target\"] + [f\"Feature_{i}\" for i in range(1, test_data.shape[1])]\n",
    "\n",
    "num_examples, num_columns = test_data.shape\n",
    "print(\n",
    "    f\"{bold}The test dataset contains {num_examples} examples and {num_columns} columns.{unbold}\\n\"\n",
    ")\n",
    "\n",
    "# prepare the ground truth target and predicting features to send into the endpoint.\n",
    "ground_truth_label, features = test_data.iloc[:, :1], test_data.iloc[:, 1:]\n",
    "\n",
    "print(\n",
    "    f\"{bold}The first 5 observations of the test data: {unbold}\"\n",
    ")  # Feature_1 is the categorical variables and rest of other features are numeric variables.\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-bangladesh",
   "metadata": {},
   "source": [
    "---\n",
    "The following code queries the endpoint you have created to get the prediction for each test example. \n",
    "The `query_endpoint()` function returns a array-like of shape (num_examples, ).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "restricted-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_tabular_data):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=content_type, Body=encoded_tabular_data\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_resonse(query_response):\n",
    "    predictions = json.loads(query_response[\"Body\"].read())\n",
    "    return np.array(predictions[\"prediction\"])\n",
    "\n",
    "\n",
    "query_response = query_endpoint(features.to_csv(header=False, index=False).encode(\"utf-8\"))\n",
    "model_predictions = parse_resonse(query_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-clinton",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Prediction Results Returned from the Endpoint\n",
    "\n",
    "---\n",
    "We evaluate the predictions results returned from the endpoint by following two ways.\n",
    "\n",
    "* Visualize the prediction results by a residual plot to compare the model predictions and ground truth targets.\n",
    "\n",
    "* Measure the prediction results quantitatively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vietnamese-divide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7AElEQVR4nO2de5gcVZn/v+90JzPTGSSQCyRgCIEESIggidx0VdTFgLuAIEQIEkjCJMYEiZddWdcV17usGzDyk1tGLiqysooggmiUVSAISTRAxFzQSCADiRp0JhlIMry/P946dE3Nqeq6nOrLzPt5nvP09OnqU6drut+3zns7xMxQFEVRlCBNtZ6AoiiKUp+oglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsFGs9AZeMHDmSx48fX+tpKIqiNBSrV6/+MzOPCvYPKAUxfvx4rFq1qtbTUBRFaSiI6E+2fjUxKYqiKFZUQSiKoihWVEEoiqIoVlRBKIqiKFZUQSiKEkl3N7BhgzwqgwtVEIqiWNm7F1i8GBg9Gpg2TR4XL5Z+ZXAwoMJcFUVxx5IlQEcH0NNT7uvokMdly2ozJ6W66ApCUZR+dHcDy5cDu3b17d+1S/rV3DQ4UAWhKEo/tm4FCgX7a4WCvK4MfFRBKIrSj7Fjgd5e+2u9vfK6MvBRBaEoSj/a2oC5c4FSqW9/qST9bW21mZdSXdRJrSiKlaVL5XH5cjEr9fYCc+aU+5WBT81XEETUQUTbiOgpX9+VRPQ8Ef3Wa6fXco6KMhgpFiVaads2YPVqeVy2TPqVwUHNFQSAmwHMsPQvZeZjvfbjKs9JURSPtjZg0iQ1Kw1Gaq4gmPmXAP5a63koiqIofam5gohgERE94Zmg9gs7iIjaiWgVEa3avn17NeenKIoyoKlXBfENAIcBOBZAJ4Cvhh3IzDcw83Rmnj5qVL8NkRRFUZSU1KWCYOYXmbmXmV8FcCOA42s9J0VRlMFGXSoIIhrje/peAE+FHasoiqLkQ80D1ojodgBvBzCSiJ4D8GkAbyeiYwEwgM0A5tdqfoqiKIOVmisIZj7f0r286hNRFEVR+lCXJiZFURSl9qiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrKiCUBRFUayoglAURVGsqIJQFEVRrNRcQRBRBxFtI6KnfH37E9FPiWij97hfLeeoKIoyGKm5ggBwM4AZgb5PAFjBzBMBrPCeK4qiKFWk5gqCmX8J4K+B7jMB3OL9fQuAs6o5J0VRFKUOFEQIBzBzp/f3CwAOCDuQiNqJaBURrdq+fXt1ZqcoijIIqFcF8RrMzAA44vUbmHk6M08fNWpUFWemKIoysKlXBfEiEY0BAO9xW43noyiKMuioVwVxN4DZ3t+zAfywhnNRlMR0dwMbNsijojQqNVcQRHQ7gJUAjiCi54hoLoAvAfhHItoI4F3ec0Wpe/buBRYvBkaPBqZNk8fFi6VfURqNYq0nwMznh7z0zqpORFEcsGQJ0NEB9PSU+zo65HHZstrMSVHSUvMVhKIMFLq7geXLgV27+vbv2iX9am5SGg1VEIriiK1bgULB/lqhIK8rSiOhCkJRHDF2LNDba3+tt1deV5RGQhWEojiirQ2YOxcolfr2l0rS39ZWm3kpSlpq7qRWlIHE0qXyuHy5mJV6e4E5c8r99UJ3N7Bxo/w9caIqL8WOriAUxSHFokQrbdsGrF4tj8uWSX89sHcv8KEPAcOHA8cdJ234cOnTUFwliCoIRcmBtjZg0qT6uzNfsgS44Ya+vpLeXulbsqR286o3NNFRUAWhKIOE7m7gppvsK4W9e+W1wS4QNdGxL4kVBBEdTkQzAn0nENE9RPQwEbW7m56iKK7YuhVoivjFNzVpKK4/0bG7Wx47Ogbv6oqkWGqCNxD9L4D9mfkU7/lIABsAtAHo8R7PYea73E61MtOnT+dVq1ZV+7SK0hB0dwOjRgEvv2x/vaUF2L69/sxi1aK7W1YM/ix4Q2ur+JMG6rUhotXMPD3Yn8bENB3Az3zPzwfwOgDHARgF4NcAPpxmkoqiuMVvS29rA+bNszvMi0V5baAKwDhoomN/0iiIUQD8l2oGgIeZ+Slm3g3guwAmu5icoijpsNnSFywALr0UuOSSvkqiUADa2+svFLfaaKJjf9IE3+0EMBwAiKgA4C0AvuZ7vQeyolAUpUbYigZef730FYuSuDd3rvyteRCCSXTs6OhbT6tUklyWwXiN0iiIdQAuIqJbAZwL8Tn81Pf6IQB0709FcUx3t5g5xo6NFlamaKDNlr5nj7TbbgOGDClXmI079kCnURIdq0UaE9NVAKZCdnm7FsBvAPzK9/qpANZkn5qiKEDy0MsoW7rBVJh96aXy2McdB4wYAbz//dI/GKn3RMdqk1hBMPO9AN4B4GoAnwFwqrdvNIhoBIDnANzsboqKMrhJGnoZZUv3UygAixaVVxs7dwK7dwN33AHst9/gzq6u10THapM4zLWe0TDXwc1ANJOkDb1cvLi/Ld32fubwsNdCAfjgB+UOeiBeW6WMyzBXRakr/CaY444DRo4E5s8fGHe/aUMvly4V23lrq/gagpRKwDnnRJuienuBG2+U6CfNLB6cVFxBEFFHinGZmeemm1J6dAUxOFm82O6UnToVWLOmse3HWZO3uruBZ58FrrlGHNPG8Tp3LvDZzwIHHgi88kr4+4tFaf5Vhonq0S1UBw5hK4g4CuLVFOdjZq7gJnOPKojBR5QABWQlcd111Z1TVoLmHJu5KI2QtpmJ5s+XQn1JGeiZxYON1CYmZm5K0aquHJTBSaX6Qrfc0jgF6MKila66qmwuamuTxzShl0HHa3c38OEPA1Om2I8vFOzmKfPaYMwsjsNAqgSrPgiloRk7NtoeXiw2jiALi1b6+Mfdhl76FdEJJwDPPANMntzXH1EoSMZ1mI9isGYWRzEQK8GqglAamrY2YPbs8NcbRZCZ5LZg1JHJVzC1lFyEXgYV0csvA5s3i1/ioYeAH/wAeO45cVDPm6dbqMZlIFaCTRXmSkRFAGcBOAHAfuivaNRJrVSNvXsleunJJ/v2N5IzdcMGueu0mSXa2mTlMGlS9vNE+WyMQ7pYLDuyr7pKVjD+zOK5c8W81cjOf9c0eiXYMB9E4n8xEe0P4BcAjgZAANh7hO9vBlB1BaEMTopFiVZatEh8DkbANVKJhGoViosKm927t685pMOLX1y2DPjiFzUPIoo44cguFHy1SWNi+hyAIwHMA3AYRCG8G8BRAG4H8DiAEa4mqChxKBYlWmn79sYskWAKxeVtzombZQ2Em7cGkhPWFQO1EmwaBfEeALcy8zcB/N3r62Xm9cx8IaSa6xddTVBRktDIJRL8yW1ZopX8BIV5mCIKwx+tVA0nbHc38PDDwF13AS+84G7cvKmWgq86zJyoAXgFQLv3974AXgVwuu/1ywE8n3RcF23atGmsKI1OVxfz+vXymJY9e5gXLWJubWVua5PHRYuk3/ZaocAshTf6ttbW8jwWLWIulfq+XipJf1b27GFesKD/+Y8+mrmnJ/v41SDqmtc7AFaxTd7bOqMagE4AS7y/mzyFMd/3+ocA7Eo6roumCqJ2uBBqip001zaOMPePW+n4ri4ReJWUSFoWLWImso8/daqMv2aNtHr/jjXib8Glgvg/ADf6nj8KYCWAZgAlyJajTyUd10VTBVF9qnnX1Ig/vCykvbZJhXlXF/O6dczt7eHnWr9e+m1jtrXJ62np6mJubraPbVpTU/nvQoF54cLGuDNvFFwqiE8C2AGg2Xt+nmdm2gmgG0AvgLlJx3XRVEFUnzzNDoZGXrpnIe21jSvMbdd1/nxRFjYlktcKYv165paWaAURbMWi2+/YYMelgiCjHHx9ZwP4PoDvAZiZdMyIc20G8CSA34Z9AH9TBVFd8jY7GKqhhOqNLNc27nuTXte8/g9xVhB5f8cGO2HyNc2GQczMrwT6vs/MZzPzucx8R9IxK3AKMx/LliQOpbakLUWdhDgZxgORLNc2TkRNmuuaR5SVme+llwJElY/1Q9Q4ZVQaFS21oaSmGrHf1VBC9UjWa1tJmKe5rnlux7l0qVSWTaIkmBs3v6BRSJNJ/R8xDmNm/myK+fQbB8ADRMQArmfmfoWJiagdQDsAjBs3zsEplbiYO9WwUtQuYr8HagJSGP6S3FmurRHmYRnQWa6ryTVxSbEIfOMbUtpj7VpJeDzxRODzn5cEyGCuRbHY4PkFjYLN7hTVIA7psNZrHpOOG3Kug7zH0QDWAnhr1PHqg6g+1XAgDwYfhO06LlwozfW1NdFg8+fX/3Xds0eugT9Po1jUKCbXIMQHkbhYHxEdYukuQspuLIEkz81m5o1JlVWF814JoJuZ/yvsGC3WVzvy3LN4716piOmqYFyec007dtSmQK7qIAWv4969wMSJwKZN9V+Ir7sb2OhJlIkTdeXgmrBifU6ijUyDRDj9CsAXHIw1DMA+vr8fATAj6j26ghjYZM2DyHO1k2XsWkeDtbcPrvwSpT9wFcUUhXeiOwFc5GC4AwA8RERrATwG4F5mvt/BuEqDkrXOUp71+rOMXetosNtu0yqtip08opiGwkE1V2b+AzMf47UpzPx5B3NTBil5hsvGGTuqAmoWh3HcyqqDNRpMyYZTBUFE0wF8GMDTLsdVlDhECcssArKSEK409oIF0RVQ01QCTVpZdbBFgymOsNmdohqAP4S0lyBRTK+ggq8gr6Y+iMFJHPt/Gjt/XL9C1NjFYv/XbJFCSX0YaSK7skSDDbY6WIMNOCy18SBkRzl/+znE9/AFAOOTjumqqYIYnMQVfC5LSwQFpu3YuGW0/cQRxGmd2mkc6QOlDpYquGicKYh6bqogBh9JhGUSYRc1bqEgxeXa2uTxwguZt2/vP/aFFzIPG2YfI0sF1DSVVf0CMomwbPQclIGi4PJGFYQyIEkjLDs7me+/Xx7TjBumNBYtYt6ypTx2XuGreSnFLOepVxpdwVWL1AoCwLg0rdK4eTRVEAOTKIFeixVElJIoFPqOvXBhPgIqL7Oanzz3gKgGA0HBVYssCsKU0EjUKo2bR1MFMbDo6ZHdxPw/7KlT+29BWU0fRJJWKomCyMPEkZdj3k+jC9hGV3DVJExBVCy14ZW4CB50BoBjAfwUwO+8vikA3gnZu+EeZv5M5MA5oKU2BhZveAPw5JP9+6dOBR55pFx64dBDgU99KroUR3e3hIL29PQfr7VVKpP6w0m7u4FnnwWuuUYSyUxpij17wsNFbZixgXzKe0SV9tiwQUJgbeG5bW1SkdVWdM8/5hVXhJcAWbbM3efIg6T/88GMs1IbAC4A8FcAx1peOw6y29z5Scd10XQF0RjEcZJ2dkbfnfujg8wWlDt2hI+bdJe1lhZZAbS0MM+cyfzYY+W9m5OYnmp5p5p0BVDNgoHVQn0Q8YDDMNcnAPxnxOufA/BE0nFdNFUQ9U0SH8D998cXwkB5C8qwze3jCsuFC2Usm0JatEjMW4sW2Y+pR1NMEgGZJKzXNXmNr1FM8XCpIHoALIp4fTGAnqTjumiqIKpD2h9zEgFUaQURtqqwrSyMMKgkLLu6wvMWjLA3x+7YwTxrVjnctVjsrzTq4U7VRbJflpwNV/PLiuZBRONSQfwBkhhHlteaIIl0f0w6roumCiJf8gqZ9OcVNDfLPgU7djBPmpRcSdhWFqZa6ZYtfYV6cP5r1lQeLygsjeDZsaO+71TDVlaGJA5dl0JdTUD1gUsFcQUksukBADMAHOq10yBO614AVyQd10VTBZEveYVMRgnjrArCtCFDyo/NzZLEtmNH3znGURCVfAr1eKcaFOgmuc//+ZOsIFwJ9UaPkhpIuFQQBOBqhIe4fi3pmK6aKoj8yDNkMm674IJwH0HSZhNolUxMtRRcWRRPWLiu8asY5357e2XB71Kopw1DrUcl3Og4UxCvvRGYBODjAL7htY8DOCLteC6aKoj8yFregTl7XgHAPHky8/vf39/XUEmwRwk0M8/OTubzzw8fqxamj6zmnEqK2Z/c19IieSZhJjhmt7kFLqKs6smM18g4VxD12FRB5EeWjOWwekUtLekEuzETnXYa8333iWmovT35yqKtreyT8JugCgXmpqby3IYMkWOyCqM0d75ZzTlJTXulkviAwubp2izkKspKyYYqCCUzWTKWzd3qrFniLDYCaP785Aoi2IpF5qFDmY88MpnCsZXi9gu7mTOZH3oo3LEbF7/CHDZMlNucOczr1uVTtTXuGGGt0tguBXWeUVZKfFIrCAAdAJYDKPieV2rLK42bR1MFkQ9JInXiCKRCQRTDunUyZrCcRpa2337MK1Yw/+AHIoTDTFpRpbj9bdiw7KaMsOQ6ouiViStzjuvkvjxMPZVWV1o2I1+yKAhTi2mo73mlNmBrMcWpBDpQsAmC9nbmxx9PFy4ZbEOGlLN1zzuvfEdPlF1RGBPWlClyx+43IRmTV1gpblvz3yF3dooCeughN8751lZZWQXHchEYsGaNZIHPn+8+uS+v34JNWegKIl/UxJSRuIXj6o08ol+MYJ8/X4SPX1m4iFbabz/m2bOzjeFvxaLM+cwzyyUz0ppejjqqf//cueHmovXr4ysi/2rC/N/mz09uztmzR5Ru0JE/d65EgmVN7rOVI6lGAUL1QeSHKoiMhJlBpk7N7ZSZyDv6JdgKBYkA8puhsgj1/feXlcrZZ/ddAbhol14qAt0mfKNaU1P4a0Zp2kxuzc3xz9HaKt8pvyPf/zzO/zGsFEiwHIlZWST9jthCjYtFUT6dnW5vSIwC6OxkvvdeMRtqFJN7clcQAKYB+EcALa7GTNryUhCVyj7Uo7mp2tEvfkVhCrxlzVcYNkwE5NlnM99xB/Mll6SLerI1s6oYN04c3H4TVJZxSyUJw/3Up5jvvlsEZXt79jHb26MzoQ1dXXLNwsZqaZGx/Apo5kxRxnGd3pX+B2mivpLckEyZwrx2rZqVXOIyUe5jkHLe/r7v+BLlNgI4IOm4LlpeCqJS4bj778/ltKmpVfSLXwiZaKVZs6LvvJMqn4suYp4xQ4S6izFNO+wwcW6bkNmgck2yCgi2uXOZjz462/yKxb75Ce3tdrPW+vXRqyIzju3axhHocbLNTcvzhiSvlftgTcJzqSBWAbjW9/wdnmP62wA+AaAbwFeTjuuiDbYVRNiX2UVSG3P2xDZzF7l9uziFW1vdmorMOfzPszi4iUTxnHwy8ymn9BXIc+Zkm+dFFzGffrp8flfXwGbWqrSCiGr+YoRh34kkCsKMmdcNidnW1YVAH+xJeC4VxJ/91VwBfA3A86Z4H4D/ArAh6bgu2mDxQVT6MmdJavOP5X8trVALVkt9/HGJWDLC16WyOOMM8S+4VERjxjA/9ZTM31U47kEHMf/612WlmXW8YHJbmA+iUKh8XVpbo8OZ45iY/C1pOG6SG5J//md3An2wO8Bdl/ue63v+FIBbfM/nANiZdFwXbbBEMdm+zC0t8oMxq5ksSW1BoR50aCYVvjahY2zf993HvO++2YWkaUSSYb1ihdiqXY07aRLz00+7qTBr2tFHMy9Y0DcaaOrU9Ks2k7OxcKGYtYJRTJdeWnl10dYmisv2nTBKaN68fPbDCN6sVDLrBT9LWoGuIbTMLhXEJgBXe38f4pmX5vhe/yiAvyYd10UbDHkQcZbiU6eW7yTTJrUZO3fw/Vu2SDTJxRfHFxKmpEUlwXf88bK6cFXFddw4MRW5EuhG0BaLzG98I/PVV5ejatLOecSIvgrCtoNbUsd8sSjvGTZMTGbnnVeu3FopwqylJVqJmMCBqVNFgEd9B7IIbLMaSrpqCwr0OL9XTcJjpwpiKYBXAHwdwOPeiuIA3+vfBLAm6bguWjUUxIoVEqO/YkXup7IS15lnTF9r10pEzQ9/mMxXYSJRbILH3N2dfbZch5kzo4VKa2t8u3ihwDxhgptkuWAbPVpMRi7HJJLw3nXr3DjOW1vlDt4fLprVF+QX1OYu3SbYSyVR5HG+X2ZFsW5d+UYimIzoIrt67dr+K8FJk8KvhxHoSVb8uoJgdqkg9gOwwls59ACY73utFcBLA81JzRzuqM5rJbFpE/NNN8mjnyTOvOHD+/fNnFm+m3SR1AYwn3su84MPytjB8UolEXiu/Q311vbdV8xlriK2jIDdsUP8NubapvWtBAVdcEc8s0LcsSP+d8I/pr8irutd5pqbmT/wAVm5Gsd0JYGe1Gfo0gfRiJFQeZT7fh2AIYG+VgDHANg/7bhZWp4KIuqH4pKuLjE7+McfMcJtdFFTkzh0t2wJ92ekEURNTcwTJ2YTOmFt//2Z/+Efso1hEybXXZc9Qil4DQ4+WP7OmgcSfH+hIIrCOOKTKN08otfyMr+EnX/y5HJob6Wkuqh5227qXEQxNXIklGZSZ2DFiugvnEtzU1A5mDZiRPkY80XMEptv2hFHML/tbWWbtSmhkTZU0gjJWbP67ljmYi8I01ybn6ZMYb71Vve5Fabtt5+7sUw2tLGtRxUk9LdKphK/oggKurRjpqHSqtZfv2vePPkNBAsqZslbcl2aplEioZwqCAD7APgPAA95iXEnef0jvf4j04ybteWlICrVBZo92815Nm2KPo/f3NTVJcXiDjnEnfAxP/p//VfJBs4i0M0PtquL+YEHmL/2Nbe5EAcfLFFbl1zCfOKJbq8BkE1Bxm0jRqRbWfn38A6W4khaXynqrtcIyzg7zbkiro8t6A/zl0+vRd5So/sxXPogRgFYD2APgKe97Ol3+F5/BsB/Jx035FwzvHNtAvCJSsc3+grippuiz3PTTfZCbMF2xBHuhNjQofIjdFXiYtgw5htuSBYFFbe5TsID7H6crK2lRcKG/cI5y3ilkgjI++8vmw3jmjni3PVW03SStHZV8P9v5haWuZ5X3lKjR0K5VBDXA/gbgOO8FcOrAQXx3wDWJh3Xcp6Cp2wmABgKYC2AyVHvaXQfRJwVRFgECsB8wgkS9cEcbqpK284+217JNG0jYj7rLOaf/Uzs6q4UUCM1E1XT1SUmuayKwoSgXnhh302Zwkh612tyYrJuoFSJrJtIlUqSX1LNvKWBuoIw2c+xIaLnAdzKzFcQ0QgA2wG8i5l/7r2+CMB/MvP+iQbuf56TAFzJzO/2nl8BAMz8xbD3TJ8+nVetWpXqfDOvXxn5+u7dwErLISedBAwdmuqUAIDeXhl76FCgUAAeeQTYs6f/cUOGACecIK+/+mr0mKUSMH48sGEDsHdv+rkFIQJaW4Fdu9yNCQBjxwKjRwMbNwI7d7odmwgoFu3XNAuFgvzvsjJsGPDGNwKvvAJs2QJs2yZzfvVVES9pIZLrethh8reNnh5g9Wr75ygUgGnT5P8NyFyeeQbo7JTxmIH99gMmTgSam9PP0wazzCvLd6GpCTj5ZPlsO3fKdc7yO43Dpk1yffy/z6YmYMwY4PDD8z03ANwx/6TU7yWi1cw8PdhfTDHWSIjJJ4xXAbSkGDfIQQC2+J4/B+CE4EFE1A6gHQDGjRvn4LR2hg4F3vY24Pnnga1b5cd30EHpx7P94A44AJg6FXjiib6C3SiH3bvjjb1rF/C738nfLS2iMHp7gb/9Lf18zZx37SoLnOZmEWxZBBkg13Pr1mxjhMFcVg5NTZWVa1yMUDX/u7Ts3ClK39xvmvFGjgQKReDFF8rjJzkXs3y3gHDhNHRo+HjMfQWq+a76r99f/iKttVWU3JAh8eZWCSJRThs3Ai++WL42ScfYvVvmlrdiMBx2mDz6f9NjxpT7GxLbsiKqAfgTgC94f49AfxPTjQB+n3Rcy3neB+Am3/MPAPh61HvyNDFt394/xr2pSfrTUGkznnPOYb7sMuaVK8vvyVKIDRB/woQJ2ZbvtjZkCPPhh/d1nLoY10WUlq259n2YlmSHujjNbM3q35QpaTRYJfNGHB9E3HyZPPwSXV3lvTuiHPFJP3eeDOo8CADfAPAigDFBBQG5w38FwJeTjms5z0kAfuJ7fgWAK6Lek6eCCEuAampKPlbSBDW/7TTKBxFX6G7axPzJT7r1U7S0SLXSBx4QYZbVjhxsw4dnL5kddj1cjmf2mXY1XrDCatwQVNNc7C8dN7LIJPeZ77hrIWnbG90WmNAooaX1hEsFcSCkeusLAG6ARDHdAuB2TzlshoNEOYj56w8ADkXZST0l6j15KYiVK6N/GP67/Dik2YzHRF+YKCbXd8EuC9uZstmTJ7udY95t4kR3uRqmFYuS5JdljDCHsQlBjbrZSFJuO0ygJ7mhsdXwMiU58siZCK4uskZYNeLdvwucKQgZC68H8EMAe70VxKueorgHwMFpxgw5z+kANkCimT5Z6fi8FMTll0f/KC6/PNl4aUtcmPhtE03y0ENi2nElzPbdN3v+g7+ZndDuvVfqIOUh1PNKbnPdDjkk/YotKgvaCMiw2kqu7qTNHtSV5mqr4WX68wiPdVXiI7iSMtFg/mTPgYxTBfHam6XcxpsAHG9WDQDeDGBFlnHTtkZZQTCnyyy+997+5oAFC/IxvQDMo0Yxv+c96UtvAPJel6uTsJaHv6K1Vcpmu86vmDaN+cYb02dB24TZaacxH3usKIpgZrELzDmzfnZz0+C6XlMe+0EA8Xfaa3ScKAjP53A8gMMtr50I4AFvJbEnybiuWqP4IJjTbcZjEyjmLnHtWuZPf9rtisK0d76T+ZZb0uVBRJXFeNe7pBKq6/mOHi05Ia7Ga2lhfve73eeWAMz77BOtgOPu4RFsxx8vSshl1nBnJ/PNNzO//vXh1ynudzlYqyupwnBdXK+SmW6g+zQyKQhI0tp1nknJ7D39CIDR3irC7Em9B8BtGGClNpjdRzEZgnbUMIE6eXL4lzj4nqOOYv7Od/Ixv0yaJELAZWLbUUe5r680ZIgk4Lmqrmr+3+95jxTLa293q4zPO6+cNJh2D4+wNmFCtu9pT499lTpmjKzc/L6GpA56f8mMuKuAJElpcXwKcXyCjZDsloWsCuJyz8/wLID/AbDGe/49ACs95XAzgMPijJdXa/T9IMLq30+dyvzEE+k2dV+7lvlzn5NHFyYC86MeMkSK/B10UPhxSRSU2Q7zrLPcVlfNu51yCvP06W7GMvb7976X+c477Xf/aQIcTFu4MJ2pJGrTHiKZ7+OPu9+7Iow4ZS2SmKDiKN1GKJeRhawKYrUXRVTy9V3rKYnt8Ir11brlqSCqXco3uBNW2k3dg59h3jw3wiyqmVDPtIJ+yhTme+5xaybyC+EZM5hHjsz/OmRthYLUrPLnQWTZw6OpKbmppFLhO//Yzc2yN0jWfcHjVJ6ttIJIaoKqVBNLVxARDUAXgI8G+o72FMTH4oxRjZangqiHUr5J787Cyhp3dTHffrv7iqUnnigOe/+S3oWD+sADmb/0JfGDuDabHXig2/H22Ufs/3mY94j6bkmaZoyWlv6b/EQJvkqls8PaxRcz3323VNttbU2WRBhn74qo32OaukiVdtpTH0RE8xTBrECfKdT37jhjVKPlpSBqXYjLliAUJ2M5joNy5UrmD31IBJsrQeZP7OvpcevcnT2befx4d+MB8tld+iqKxbKpyOU8TTvvPPGBpPEDlUri84q7Go67grA1YzKbOVNWQfPnu4naMvtBBPfuNp8hS2XVsJ32NIoponmK4IJAX78yG7VueSmItF+4rEk3YWYtf9RH0q0VDbY9eydNYv7CF6L9CnGbOX9np4Tnnnde9jH9gqe52X1S28yZYoJ73/uYTz01u9Iwd54/+pFkmbvcEa+lRUw5556b/H1J93eI8kHEbYVCf6FeKMTbu6LSaiH4G3NxQzfYEuZcKIhvAfiIr/2755z+RqD/IwCWxBnXdauXFYQrf0Ucs1aSzdn9RCmWPXvcOIqPPLLv88mTpWy4ywgo4zDPY89rIubDDsumKIKb+5x9tjj3XURt+YXkHXcwX3RRtCmnWCxHy8X5Lhsh+cc/SpZ51vn6N5GyrYiTRm1FCft6MAk3Ei4URJLWG2dc161efBAuvpxJfxhBp3YUcXfcMrvBffWrzD/+sRt/wtSpMv4PfsD84IPukujMpjn33isb3Ls0GeWxV0WhICuVRx9Nby4C7ImIBx3UPwTX3MGvWxc/Asif1zBkiPhVTj45m4kvqmyITdinXb038v7QtSCrgnhb0hZnXNetHqKYXPkr8tyhKs6evWF230suyS4c/fbdhQvFVJIlW9s/rrlDLpXc51b4/48uxjb7S3d1iY0+qbkIqDyPCROYv/vdeNFwURFAwTZ5siiMpNch6Xc36+9psJmK0pJLqY16a9XIg6j0hXMl2PN0jMdZQUStgjo7mTs6xF9x6KHJhVrYmPfeK2aStGPZ6gC1tor9/4orpNZUVqHub+eeK/tiDxmSvnhiU1NfhWn8Ci6joEzxxHPOEUUU5YOIG0ZbKMg469ZJxFLcFVua766ai/JHFUSVcCnY8/xhRPkgoj5DodBXGDQ19a9WmrQkh4n6MUKyvV1MWwcfnF4ohjWXSsKUt+7qkkSx887r629IG2Vkxly7NvpaplUiTU3iUxgyRM4XNwLI9vnN97mzU7L3b7tNTH0uw0XzMhfltbpIYu6tF1RBVBFXgj1PO2qUcztptm6xKKYn/48iS+SL/1pt2sT89a8z33df2XxkM0UlMVFNniz+j9NOK5eKyKIk/OWmm5slGsrvgE06ZvBGwqyuTE6B+S64yjifMqUc1JAkEc+EzC5c2FcZFgpS5PCCC9yFixq/1UMPZRfoef2u0gaM1AOqIKqI6y9gnnbUTZuYb7pJHv3nSyrY/HeTzPYfSxJ7tW1fARPiu25d/9fa25Ml/vlt8uvXS62iNFVxw8pbT5kiK4CwUtxRLUnotIsQVDPfNWvKmz3FCSE2ytH2+fz+FTNumu9vHkI3r5V52pDzekAVRA2oZwdZJSWWNGu7VLILNf9yO8mYNsFr2wrTf32TjB+WZe5fsbS3ZxO6xnR27rkSsRS8yw6z2ycxRdoEaNbW1CTKsqUlXKkXi5WVcnNz9s18XAvdvHx7cSMD6xVVEEofKt1F2RRIlE09uIKwkXTMpD9i//iVSjvY6lTZFGZnpyQQhn3muGatuPtLp72TXb2a+U1vSnYtKyk3EzY8a1Z/5WZCZqMUslGQaT9fHkI3r+jAOJGB9YwqCOU10pZLDqtVY8wJSc4fVVMnSvDG+RGb8cNyLGx3n5WE9ZYtErHkL2/d3p5soyL/vgKmzLvNjJbkDtu2gpgwgXn5cnnMqijM5kOXXML8ve/19QF0daWr5xX3Tj0PoasrCDuqIJTXyJJ8FNwP29xNpvWv2O7co/YVyGp+sdmv4woNmz19/vxkwjHo1G5tlcS+66/v6weKS5R5adgwt7kg/m1DTbmXMB+EKd+e9DvmJy+hqz6I/qiCUF7DRfJRFsejjWBooMsfcaWww0oKM6q43Z49yXwAYU5t0yZNir+5T9JCegcfLII7q9Lwb/IzdKhEhQVNUPPmuVHyeQhdjWLqjyoIpQ/1knwU9mPt6aleqYRKCtMW1eO/Vjt2SA7E0KHpE+aCLc5nTVOKu1BgvvBC5t//Xt5/ySVu5jx5suSC+G8aXHzH8hS6mgdRRhWE0od6qVVTSYhUKxIsbB7GR2ATikFzUUuLxP5ffLHd+Z7EqW2S8KKuQdpS3H5fiDEbuqg31d7ed34uv2MmuuyBB+ozKrDRUQWhWKllKG6t99nwEybMoorb2cxFxvxSKkm4qH+/5aS5GjZ/RVDApg1xtQUjGLOhrRRHnNbcbA9w6OxM/x2zKbCsfi+lP6oglLojz4KEaQkqzDRJg8HW1CRC1yghl7kgafMgonZt80dXJSmgOGxY8v2gK+Eqck6JRhWEUnfU0woiiqShuGGfxwhJIzzTliSPKve+ZUu4UI0aIyya7JFHpHSIKZkRZYqKqgZbKcnRRqUw2ji5N0o8VEEodUm9OMujsAnPpOaioFDu6mJ+4glx7oYJvyxhombrTJsSirtrmz9aqbmZ+YwzZPMg24rFKMBKSt+2SZCpChsU9uvXR6+2wrL3leSoglDqknpxlschS2mPKMEeloTnIkx0xw6JWoq6vknMaMb+P2+ezNck0sWpBtvWJkrLds38ORZmbrqCqB6qIJS6pp7rVoURVG7mjjuJachPHAWUdnWVdte2sM9hypAEwzkrrSAqrbpKJTFtuc7eV6JRBaEoORG0/9uURL2Ve/eTxhEf3MOjUqHHUklWMnEVkVmZLFzIvGCB2+x9pT+qIBTFMWECfPv2ymadJFRjdZXUXBalAMOuy44dyRWRGVfzIPIlTEGQvDYwmD59Oq9atarW01AGCYsXAx0dwK5d5b5SCZgzB1i2DOjuBrZuBcaOBdraajfPOOzdCyxZAixfDhQKwMsvi4ju7Y0/RmsrsG1b+bO+8AKwdi1wzDHAgQdKn+2aVYJI5mKYOhV47DGgpSX+GEo0RLSamacH+5tqMRlFaXS6u0WYBgXdrl3S390tgnLSpPpXDgBQLIpS27YNWL0a2L4d+OAHRVnEpVAQhbh3ryiCCROA971PHhcvlv6lS0WBtrYCQ4bEGzd4D/vkk8Dxx8efl5KeulQQRHQlET1PRL/12um1npOi+Nm6NVx4GkHZiBilNny4KIw//xm48EIR6G1t8hj2uXt7ZbW0ZImsEnp6RFH29MjzJUv6KqLf/haYP788dhKefFJWKEq+1KWC8FjKzMd67ce1noyi+Bk7Ntz8YgTlQGD4cOC228ori23bZGVRKvU9rlQC5s6VvyutrABRCJMnA9ddVx67vb3/uFGsXZv6YykxqWcFoSh1S1ubCMQwQdkIZqUk+M1lfjORWVXMmSP9aVZWZuxrr+07biUfwzHHZP9cSjR16aQmoisBXAzg7wBWAfgoM+8IObYdQDsAjBs3btqf/vSnKs1SGewEHbu9vaIcli4VU8pAx+aE7+4GRo8Ws1KQoBM7zrgnnyzmpCBTpwJPPJH9MyhCmJO6ZgqCiH4G4EDLS58E8CiAPwNgAJ8FMIaZ51QaU6OYlFrQSNFK1aBSdFcSXn5ZHNJ+JaFRTO4JUxA1u89h5nfFOY6IbgTwo5ynoyipMSYSRVi6VB79KytjgkpKS4usFF54AXj0UWDUKDEtqXKoDnXpgyCiMb6n7wXwVK3moihKMoIhs9u2yfO0Zre9e4HPfx644AJgxgwxYZmwWSVf6tVS+hUiOhZiYtoMYH5NZ6MoSmJcraz8YbOGjg55TGqyUpJRl07qtKgPQlEGFnGd3uoHyoZmUiuK0nBUCpt99lkxN40eDUybpuYn19SriUlRFKViQuI11wDf+paan/JCVxCKotQtUQmJF10kWd6VsraV9KiCUBSlrgnL3L7ssoFZD6ueUBOToih1jQmb/eIX+zqiu7sHRz2sWqIrCEVRGoJg+fTBVg+rFugKQlGUhsVl1rbSH82DUBSl4dE8iGzUXS0mRVEUV2g9rHxQH4SiKIpiRRWEoiiKYkUVhKIoimJFFYSiKIpiRRWEoiiKYkUVhKIoimJFFYSiKIpiRRWEoiiKYkUVhKIoimJFFYSiKIpiRRWEoiiKYkUVhKIoikO6u4ENGwbGjnaqIBRFURywdy+weDEwejQwbZo8Ll4s/Y2KVnNVFEVxwJIlQEcH0NNT7uvokMdly2ozp6zoCkJRFCUj3d2yadGuXX37d+2S/kY1N6mCUBRFycjWrbKjnY1CQV5vRFRBKIqiZGTsWNnu1EZvr7zeiKiCUBRFyUhbGzB3LlAq9e0vlaS/UbdBVSe1oiiKA5Yulcfly8Ws1NsLzJlT7m9EiJlrPQdnTJ8+nVetWlXraSiKMojp7hafw9ixjbNyIKLVzDw92K8rCEVRFIe0tQGTJtV6Fm5QH4SiKIpiRRWEoiiKYkUVhKIoimJFFYSiKIpiZUBFMRHRdgB/Svn2kQD+7HA6edNI822kuQKNNd9GmivQWPNtpLkC2eZ7CDOPCnYOKAWRBSJaZQvzqlcaab6NNFegsebbSHMFGmu+jTRXIJ/5qolJURRFsaIKQlEURbGiCqLMDbWeQEIaab6NNFegsebbSHMFGmu+jTRXIIf5qg9CURRFsaIrCEVRFMWKKghFURTFiioIAERUIKLfENGPaj2XShDRcCK6k4h+T0RPE9FJtZ5TFES0hIjWEdFTRHQ7EbXUek4GIuogom1E9JSvb38i+ikRbfQe96vlHP2EzPcq77vwBBH9gIiG13CKr2Gbq++1jxIRE9HIWszNRth8iWixd33XEdFXajU/PyHfg2OJ6FEi+i0RrSKi412cSxWE8GEAT9d6EjG5BsD9zHwkgGNQx/MmooMAXAZgOjMfDaAA4P21nVUfbgYwI9D3CQArmHkigBXe83rhZvSf708BHM3MbwCwAcAV1Z5UCDej/1xBRK8HcCqAZ6s9oQrcjMB8iegUAGcCOIaZpwD4rxrMy8bN6H9tvwLgM8x8LID/8J5nZtArCCI6GMB7ANxU67lUgoj2BfBWAMsBgJl3M/NLNZ1UZYoAWomoCKAEoG5252XmXwL4a6D7TAC3eH/fAuCsas4pCtt8mfkBZt7rPX0UwMFVn5iFkGsLAEsB/AuAuoqOCZnvBwF8iZlf8Y7ZVvWJWQiZKwN4nff3vnD0Oxv0CgLA1ZAv7Ks1nkccDgWwHcA3PZPYTUQ0rNaTCoOZn4fcdT0LoBPA35j5gdrOqiIHMHOn9/cLAA6o5WQSMgfAfbWeRBhEdCaA55l5ba3nEpNJAP6BiH5NRP9HRG+q9YQiuBzAVUS0BfKbc7KSHNQKgoj+CcA2Zl5d67nEpAjgOADfYOY3AtiJ+jKB9MGz358JUWxjAQwjogtrO6v4sMSA19WdbhhE9EkAewF8u9ZzsUFEJQD/BjF/NApFAPsDOBHAxwH8DxFRbacUygcBLGHm1wNYAs/KkJVBrSAAvBnAGUS0GcB3AbyDiL5V2ylF8hyA55j5197zOyEKo155F4A/MvN2Zt4D4PsATq7xnCrxIhGNAQDvsS7MClEQ0cUA/gnALK7fxKbDIDcKa73f28EA1hDRgTWdVTTPAfg+C49BrAx141gPMBvy+wKA7wFQJ3VWmPkKZj6YmcdDnKc/Z+a6vcNl5hcAbCGiI7yudwL4XQ2nVIlnAZxIRCXvzuudqGOnusfdkB8bvMcf1nAuFSGiGRAT6RnMvKvW8wmDmZ9k5tHMPN77vT0H4DjvO12v3AXgFAAgokkAhqJ+q7tuBfA27+93ANjoYlDdk7rxWAzg20Q0FMAfAFxS4/mEwsy/JqI7AayBmD9+gzoqX0BEtwN4O4CRRPQcgE8D+BLElDAXUjr+vNrNsC8h870CQDOAn3rWj0eZeUHNJulhmyszOzF75EHIte0A0OGFk+4GMLseVmghc70UwDVeMMjLANqdnKsOPq+iKIpShwxqE5OiKIoSjioIRVEUxYoqCEVRFMWKKghFURTFiioIRVEUxYoqCGVAQUTjvUqhV0b11RNEdDMR1TSckIge9BLYFOU1VEEomSGit3sC2N+6iWg1EX2YiAq1nmNaPOVyJREdW+N5vMe7rldXOO4z3nEXVGlqygBGE+UUl9wO4McACFJ76WJIMcQpcJS4k5I/AWiFJOslZTwkEWkzgN86m1Fy7odky84ioo97pUv64GWrzwbwEsplFxQlNbqCUFyyhpm/xcy3MfOXAZwAEWrziCi0KioR7ZPnpLxaOi/7ymI3HMzcC9kHYCSAfw457B0ADgHwHWZ+uUpTUwYwqiCU3GDmvwNYCVlRTAAAItrs2bvfSEQ/IaK/AXjCvIeIJhLRbUTUSUS7veOvspU1J6K3ENHDRNRDRC8S0dcBtFmOC/VBENE53nxeIqJdRLSeiL5GREO9Ini/8A79ps989qDv/UREH/TMabs809ovvM1mgudq8T7LVm/OjxHRqQkuaQekuuyckNfn+I4DEc0koruJ6FkieoWI/kxEdxHRG+KczPyvLP3GpHhxoL+ZiP6NZPe1l71reg8RvTFwXBMRXU6yC14XEf3du+7LiWhInLkp1UFNTEpueCaPw72n/iJn4wD8HFJ18n/hCXUimub1vwTgegDPQ3bNuwzAm4nobca0QkQnAPgZgC4AX/be834AtyaY3+chJah/B9nIphNSdfQcSFnqXwL4gnfMDQB+5b31Rd8wtwE4H1JZ95uQukizILWRzmbmu33H3g7ZgOgeAD/xzvV9AH+MM19mfoaIfglgBhGN8e1bYTaTei+Atb7y9YsA/MWb+wve+doBPExExzGzk4Ju3vmHQMxgJ0OuydchG9dc6p3vrcy8yjv8kwD+E3IdrgPQC6n0egbk+vUznyk1gpm1acvUIIXDGCJURwIYBeANAG70+lf6jt3s9c2zjLMWwO8B7BPof6/3not9fY9ACqhN8vUNBfCYd+yVvv7xlr7jvb6fA2gJnI9QrlP29uC5LfNqD/QXAayCCH4zzqnesTcHjj3L6+eY1/oD3vH/Euif7/Vf5usbZnn/UQBeAfD/Av0PAtgc6NsM4MGI/7f//7HE63t34NjXQar6PujrWwPgd7X+3mqr3NTEpLjkM5Ad77ZBhP0cSPnsswLH/RVyt/0aRDQVolS+A6CZiEaaBuAhyOZIp3rHjgZwEoAfMvMGMwYz74asBOIwy3u8ggP2evaIMcaFkBXMXYH5DofcHY8HMNE79izv8arAue4CsD7mnAFZqfwN/av4XgIR/K/tZ8LMO4HXzGCv8+a23TvfCQnOGYcLIcp9deBaDIXsm/0WImr1jv0bgIOI6C2O56A4Rk1MiktugJiNGCLQNzCzbV/iZ1icrn6O8h4/4zUbxtE9wXv8veWYuPtjTPTmmWX7y6MA7IO+JqcgBwDYAJnzq97fQZ4GcISlvx/M3ENS7nkBEZ3EzCuJaDJE4P+P/3p7tv/PQu74gz6cWGatBBwFiRTbHnHMSABbICa7uwD8ioi2QlYv9wK401PySp2gCkJxyUZm/lmM42wb25itHL8KsWXb2JFqVuFk3VKUIAIxKufgqQzjh9EBYAFk1bAS5dXEa/stENE4iA/l7xAlsR6itBkSetzPmW8h7NrY5AYBeBLARyLG2w4AnlI7DMC7IRvynAK5hv9ORG8JualQaoAqCKVeMA7T3hhKxtz9Hml5bXLM820AcBrECf5YxHFRCmQjZGP7R5m5u8L5/gCJGpwEYF3gtaP6Hx4xIebHiehJADOJ6GMQv8SzEKe94b0QJXAGM//C/34iGgExR1Xir5A9mYNMsPRthPiefs7Mr8b4DN2QAIX/9ea0EMC1AOYiYIZTaof6IJR64TeQu+0FRNRPABFRkYj2BwBmfhHAowDOJNkK0hwzFOIsjcN3vMcveO8Lns+saIzgtwnKWyG/oS/aTkB9cz/M1qUfDxxzFmKalwIshziAb4KYsW4OCGZjwiP/m4joUgBx94HeAOBIIjrI9/5mAB+yHHurN651BeG/Fp5vIsga79F2nZUaoSsIpS5gZiaiD0Ciip4gog7InXYJEip7NmR7zZu9t3wEYrt+mIiuRTnMNdZ3mpkfI6IvA/hXAGuI6A5IKOihAN4HiXJ6CeLT6AKwkIh2eX3bmPnnzHwnEX0TwCIiOg7AjyDhvAdDnOiHw7vbZuafENE9AGZ7iu5+SNjpfIhiPDrZFcO3AHwFwLmQVc43A6/fBzHl3eblh+wA8GYApwN4BvGu09ch1/RnRHQdxOH8AdhNhNcA+EcAVxHROyD/x79DQprfCdkG0+SGPE1EjwL4NSSRcgwk/HY3gO/GmJdSLWodRqWt8RvKYY8fi3HsZlhCJ32vHwKJjd8MERh/AbAacpf++sCxb4WEu74McRRfCxG0FcNcfa+dD+BhiBLYCXF8Xw1gqO+Y0yF3uC974zwYGOMDkByJv3vHbIbkN8wMHNcK8bG8AKAHYto6FaL0OMV1v8Obz4qQ198KiQDrgii2e73r8yD6h7T26/P6Z0P8F7shpr1/gWRs9wv9hSidywA87l3LnRDT07cBnOo77hMQ/8g2iKlrCyS44bhaf5e19W26J7WiKIpiRX0QiqIoihVVEIqiKIoVVRCKoiiKFVUQiqIoihVVEIqiKIoVVRCKoiiKFVUQiqIoihVVEIqiKIoVVRCKoiiKlf8P70mEd/gBZlEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization: a residual plot to compare the model predictions and ground truth targets. For each example, the residual value\n",
    "# is the subtraction between the prediction and ground truth target.\n",
    "# We can see that the points in the residual plot are randomly dispersed around the horizontal axis y = 0,\n",
    "# which indicates the fitted regression model is appropriate for the ABALONE data\n",
    "\n",
    "residuals = ground_truth_label.values[:, 0] - model_predictions\n",
    "plt.scatter(model_predictions, residuals, color=\"blue\", s=40)\n",
    "plt.hlines(y=0, xmin=4, xmax=18)\n",
    "plt.xlabel(\"Predicted Values\", fontsize=18)\n",
    "plt.ylabel(\"Residuals\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "collectible-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mEvaluation result on test data\u001b[0m:\n",
      "\u001b[1mr2_score\u001b[0m: 0.5370647997308744\n",
      "\u001b[1mmean_squared_error\u001b[0m: 5.297819866056932\n",
      "\u001b[1mmean_absolute_error\u001b[0m: 1.6110351101677107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model predictions quantitatively.\n",
    "eval_r2_score = r2_score(ground_truth_label.values, model_predictions)\n",
    "eval_mse_score = mean_squared_error(ground_truth_label.values, model_predictions)\n",
    "eval_mae_score = mean_absolute_error(ground_truth_label.values, model_predictions)\n",
    "print(\n",
    "    f\"{bold}Evaluation result on test data{unbold}:{newline}\"\n",
    "    f\"{bold}{r2_score.__name__}{unbold}: {eval_r2_score}{newline}\"\n",
    "    f\"{bold}{mean_squared_error.__name__}{unbold}: {eval_mse_score}{newline}\"\n",
    "    f\"{bold}{mean_absolute_error.__name__}{unbold}: {eval_mae_score}{newline}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-stock",
   "metadata": {},
   "source": [
    "---\n",
    "Next, we delete the endpoint corresponding to the finetuned model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pacific-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint and the attached resources\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eaaaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
