{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural Architecture Search for Large Language Models\n",
    "\n",
    "Neural Architecture Search (NAS) is an effective framework to design neural network architectures automatically.\n",
    "This notebook demonstrates how to utilize NAS for compressing a large language model that has been fine-tuned for a specific target task. The main objective is to reduce the model size while maintaining performance as much as possible. To achieve this, we search for sub-networks within the model that jointly optimize the parameter count and validation error.\n",
    "\n",
    "Sub-networks can be defined in various ways. In this context, we consider subsets of multi-head attention and fully-connected layers, with a reduced number of heads in the multi-head attention layer and units in the intermediate layers.\n",
    "\n",
    "Our NAS approach consists of two steps:\n",
    "\n",
    "1. Initial fine-tuning of the pre-trained model on the target task using weight-sharing based NAS training strategies. The pre-trained model serves as a 'super-network' that encompasses a large, finite set of sub-networks. To prevent sub-networks from co-adapting, we modify the fine-tuning process by updating only specific parts of the network (i.e., subsets of all layers) in each update step.\n",
    "\n",
    "2. In the second step, we employ multi-objective search through [SageMaker Automated Model Tuning (AMT)](https://aws.amazon.com/sagemaker/automatic-model-tuning/) to identify a set of sub-networks that offer an optimal trade-off between parameter count and validation error for the target task.\n",
    "\n",
    "Finally, we can visualize the so-called **Pareto set** of architectures that optimally balance between parameter count and validation error, and select the best-suited model that strikes the right balance between model size and validation error for us.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- Currently, the notebook limited to the BERT model family.\n",
    "- We exclusively focus on supervised fine-tuning using labeled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset \n",
    "\n",
    "For illustration purposes, we use the [Recognizing Textual Entailment](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) dataset from the [GLUE](https://gluebenchmark.com/) benchmarking suite. For simplicity, we load the dataset via the [dataset library](https://huggingface.co/docs/datasets/index) from HuggingFace inside our training script.\n",
    "The goal of this dataset is to identify whether the meaning of one sentence can be infered from the other sentence. \n",
    "Example sentence pair:\n",
    " \n",
    "sentence 1:\n",
    "*Only a week after it had no comment on upping the storage capacity of its Hotmail e-mail service, Microsoft early Thursday announced it was boosting the allowance to 250MB to follow similar moves by rivals such as Google, Yahoo, and Lycos.*\n",
    "\n",
    "sentence 2:\n",
    "*Microsoft's Hotmail has raised its storage capacity to 250MB.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "hyperparameters = dict()\n",
    "\n",
    "hyperparameters[\"seed\"] = seed\n",
    "hyperparameters[\"output_dir\"] = \"/opt/ml/checkpoints\"\n",
    "hyperparameters[\"task_name\"] = \"rte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split Dataset in Training / Validation\n",
    "\n",
    "As mentioned earlier, after fine-tuning our 'super-network' on the training dataset, we proceed with a multi-objective search to identify the optimal set of sub-networks that optimally balance between generalization performance and parameter count. Since we cannot directly compute generalization performance, we approximate it by measuring accuracy on a hold-out validation dataset.\n",
    "\n",
    "To achieve this, we split the original training dataset from GLUE into an training/validation set. The training set is exclusively used for fine-tuning purposes, while the validation data is employed for the subsequent multi-objective search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-trained Model\n",
    "\n",
    "We use the [pre-trained BERT model](https://huggingface.co/bert-base-cased) from the HuggingFace hub, which consists of 12 layer with 12 heads in each multi-head attention layers and 3072 units in the fully connected layers. See [Devlin et. al.](https://aclanthology.org/N19-1423/) for a more detailed description of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"bert-base-cased\"\n",
    "hyperparameters[\"model_name_or_path\"] = model_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train weight-sharing based Super-Network\n",
    "\n",
    "We now fine-tune our pre-training network, i.e super-network with the following hyperparameters. We have to pass an additional argument to specify if our dataset is regression or not (determines the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters[\"per_device_train_batch_size\"] = 8\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 8\n",
    "hyperparameters[\"learning_rate\"] = 2e-05\n",
    "hyperparameters[\"num_train_epochs\"] = 5\n",
    "hyperparameters[\"save_strategy\"] = \"epoch\"\n",
    "hyperparameters[\n",
    "    \"is_regression\"\n",
    "] = False  # set this to True if your dataset is a regression dataset, for example STSB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the checkpoint of the model on S3, such that we can load it later in the second phase for the multi-objective search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = Session()\n",
    "s3_bucket = session.default_bucket()\n",
    "s3_bucket_prefix = \"nas_amt/model_checkpoint\"\n",
    "s3_path = f\"s3://{s3_bucket}/{s3_bucket_prefix}\"\n",
    "\n",
    "sm_args = dict(\n",
    "    entry_point=\"training.py\",\n",
    "    source_dir=os.path.abspath(\"\"),\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    instance_count=1,\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    transformers_version=\"4.26\",\n",
    "    max_run=3600 * 72,\n",
    "    role=get_execution_role(),\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    checkpoint_s3_uri=s3_path,\n",
    ")\n",
    "\n",
    "est = PyTorch(**sm_args)\n",
    "est.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-objective search for sub-networks\n",
    "\n",
    "After the fine-tuning process, we begin the multi-objective search by sampling random sub-networks using AMT. A sub-network is defined by its number of layers, heads, and units in the intermediate fully connected layers. To access a sub-network, we place a binary mask over the super-network and mask out all components (i.e., heads, units) that are not part of the sub-network. Note that, HuggingFace transformers needs the hidden size to be a multiple of the number of head. We cannot change the hidden size, and hence the number of heads has to be in [1, 3, 6, 12].\n",
    "\n",
    "In contrast to single-objective optimization, in the multi-objective setting, we typically do not have a single solution that simultaneously optimizes all objectives. Instead, we aim to collect a set of solutions that *dominate* all other solutions in at least one objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can start the multi-objective search through AMT. We sample a total of 100 random sub-networks (defined by the parameter `max_jobs`) and evaluate 10 networks simultaneously (defined by `max_parallel_jobs`). The code to load the model checkpoint and evaluate the sub-network is available in the `evaluate_subnetwork.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Maximum number of sub-networks we will evaluate\n",
    "max_jobs = 100\n",
    "max_parallel_jobs = 10\n",
    "\n",
    "# Entry point script to load the super-network and evaluate a sub-network\n",
    "entry_point = \"evaluate_subnetwork.py\"\n",
    "\n",
    "# Command line arguments for the entry point script\n",
    "hyperparameters = {\"model_name_or_path\": model_type, \"output_dir\": \"./tmp\", \"task_name\": \"rte\"}\n",
    "\n",
    "# Define the metric we want to maximize\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"num-parameters\", \"Regex\": \"number of parameters: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation-performance\", \"Regex\": \"validation score: ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "# Define HuggingFace estimator\n",
    "estimator = HuggingFace(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=\"./\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",  # instance types for the SageMaker training jobs\n",
    "    instance_count=1,\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    transformers_version=\"4.26\",\n",
    "    max_run=3600 * 72,\n",
    "    role=get_execution_role(),\n",
    "    volume_size=125,\n",
    "    model_uri=s3_path,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "tuning_job_name = f\"nas-search-{current_time}\"\n",
    "\n",
    "# Search space to define sub-networks\n",
    "hyperparameter_ranges = {\n",
    "    \"num_layers\": IntegerParameter(0, 12),\n",
    "    # To meet HuggingFace constraints, we can only set the number of head to these values\n",
    "    \"num_heads\": CategoricalParameter([1, 3, 6, 12]),\n",
    "    \"num_units\": IntegerParameter(0, 3072),\n",
    "}\n",
    "\n",
    "# Define AMT Tuner object\n",
    "my_tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=\"validation-performance\",\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_jobs=max_jobs,\n",
    "    strategy=\"Random\",\n",
    "    random_seed=seed,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    ")\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "my_tuner.fit(job_name=tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize Results\n",
    "\n",
    "To visualize our results, we parse AMT's history to collect all configurations of sub-networks and the corresponding metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = my_tuner.analytics().dataframe()\n",
    "data = []\n",
    "configs = []\n",
    "for i, t in enumerate(my_tuner.analytics().training_job_summaries()):\n",
    "    jn = t[\"TrainingJobName\"]\n",
    "    df = sagemaker.analytics.TrainingJobAnalytics(jn).dataframe()\n",
    "\n",
    "    row = history[history[\"TrainingJobName\"] == jn]\n",
    "    config = {\n",
    "        \"num-heads\": int(row[\"num_heads\"].iloc[0].strip('\"')),\n",
    "        \"num-layers\": int(row[\"num_layers\"]),\n",
    "        \"num-units\": int(row[\"num_units\"]),\n",
    "    }\n",
    "    configs.append(config)\n",
    "\n",
    "    p = []\n",
    "    for j, metric in enumerate(metric_definitions):\n",
    "        metric_name = metric[\"Name\"]\n",
    "        if \"metric_name\" not in df.keys():\n",
    "            continue\n",
    "\n",
    "        if metric_name == \"validation-performance\":\n",
    "            y = 1 - float(df[df[\"metric_name\"] == metric_name][\"value\"])\n",
    "        else:\n",
    "            y = float(df[df[\"metric_name\"] == metric_name][\"value\"])\n",
    "        p.append(y)\n",
    "    if len(p) > 0:\n",
    "        data.append(p)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now visualize the Pareto set, which represents the optimal set of sub-networks that dominate all other sub-networks in at least one metric. This implies that when we move from one sub-network of the Pareto set to another, we must either sacrifice performance or model size but improve the other.\n",
    "\n",
    "Ultimately, the Pareto set provides us the flexibility to choose the sub-network that best suits our preferences. We can decide how much we want to reduce the size of our network and how much performance we are willing to sacrifice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from multi_objective import get_pareto_optimal\n",
    "\n",
    "idx = get_pareto_optimal(data)\n",
    "x = data[idx, 0]\n",
    "y = data[idx, 1]\n",
    "\n",
    "plt.scatter(\n",
    "    x, y, marker=\"o\", s=80, facecolors=\"none\", edgecolors=\"C0\", linewidth=2, label=\"Pareto front\"\n",
    ")\n",
    "plt.xlabel(\"number of parameters\")\n",
    "plt.ylabel(\"validation error\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(linewidth=\"1\", alpha=0.4, which=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Model\n",
    "\n",
    "Base on the Pareto front above, we can select the best model for our use case and deploy it on an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data='s3://sagemaker-us-west-2-770209394645/nas_amt/model_checkpoint/model.tar.gz',  # path to your trained SageMaker model\n",
    "   role=get_execution_role(),                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.26\",                           # Transformers version used\n",
    "   pytorch_version=\"1.13\",                                # PyTorch version used\n",
    "   py_version='py39',       \n",
    "   entry_point='inference.py',\n",
    "    source_dir=\"./\",\n",
    "    env={'SM_HPS' : 'f{\"num-layers\": \"{configs[i]['num_}\", \"num-heads\": \"6\",\"num-units\": \"1024\"}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "   \"inputs\": [('No Weapons of Mass Destruction Found in Iraq Yet', 'Weapons of Mass Destruction Found in Iraq.')]\n",
    "}\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are done we can delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
