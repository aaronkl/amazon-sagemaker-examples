{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural Architecture Search for Large Language Models\n",
    "\n",
    "Neural Architecture Search (NAS) is an effective framework to design neural network architectures automatically.\n",
    "This notebook demonstrates how to utilize NAS for compressing a large language model that has been fine-tuned for a specific target task. The main objective is to reduce the model size while maintaining performance as much as possible. To achieve this, we search for sub-networks within the model that jointly optimize the parameter count and validation error.\n",
    "\n",
    "Sub-networks can be defined in various ways. In this context, we consider subsets of multi-head attention and fully-connected layers, with a reduced number of heads in the multi-head attention layer and units in the intermediate layers.\n",
    "\n",
    "Our NAS approach consists of two steps:\n",
    "\n",
    "1. Initial fine-tuning of the pre-trained model on the target task using weight-sharing based NAS training strategies. The pre-trained model serves as a 'super-network' that encompasses a large, finite set of sub-networks. To prevent sub-networks from co-adapting, we modify the fine-tuning process by updating only specific parts of the network (i.e., subsets of all layers) in each update step.\n",
    "\n",
    "2. In the second step, we employ multi-objective search through [SageMaker Automated Model Tuning (AMT)](https://aws.amazon.com/sagemaker/automatic-model-tuning/) to identify a set of sub-networks that offer an optimal trade-off between parameter count and validation error for the target task.\n",
    "\n",
    "Finally, we can visualize the so-called **Pareto set** of architectures that optimally balance between parameter count and validation error, and select the best-suited model that strikes the right balance between model size and validation error for us.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- Currently, the notebook limited to the BERT model family.\n",
    "- We exclusively focus on supervised fine-tuning using labeled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset \n",
    "\n",
    "For illustration purposes, we use the [Recognizing Textual Entailment](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) dataset from the [GLUE](https://gluebenchmark.com/) benchmarking suite. For simplicity, we load the dataset via the [dataset library](https://huggingface.co/docs/datasets/index) from HuggingFace inside our training script.\n",
    "The goal of this dataset is to identify whether the meaning of one sentence can be infered from the other sentence. \n",
    "Example sentence pair:\n",
    " \n",
    "sentence 1:\n",
    "*Only a week after it had no comment on upping the storage capacity of its Hotmail e-mail service, Microsoft early Thursday announced it was boosting the allowance to 250MB to follow similar moves by rivals such as Google, Yahoo, and Lycos.*\n",
    "\n",
    "sentence 2:\n",
    "*Microsoft's Hotmail has raised its storage capacity to 250MB.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "hyperparameters = dict()\n",
    "\n",
    "hyperparameters[\"seed\"] = seed\n",
    "hyperparameters[\"output_dir\"] = \"/opt/ml/checkpoints\"\n",
    "hyperparameters[\"task_name\"] = \"rte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split Dataset in Training / Validation\n",
    "\n",
    "As mentioned earlier, after fine-tuning our 'super-network' on the training dataset, we proceed with a multi-objective search to identify the optimal set of sub-networks that optimally balance between generalization performance and parameter count. Since we cannot directly compute generalization performance, we approximate it by measuring accuracy on a hold-out validation dataset.\n",
    "\n",
    "To achieve this, we split the original training dataset from GLUE into an training/validation set. The training set is exclusively used for fine-tuning purposes, while the validation data is employed for the subsequent multi-objective search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-trained Model\n",
    "\n",
    "We use the [pre-trained BERT model](https://huggingface.co/bert-base-cased) from the HuggingFace hub, which consists of 12 layer with 12 heads in each multi-head attention layers and 3072 units in the fully connected layers. See [Devlin et. al.](https://aclanthology.org/N19-1423/) for a more detailed description of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"bert-base-cased\"\n",
    "hyperparameters[\"model_name_or_path\"] = model_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train weight-sharing based Super-Network\n",
    "\n",
    "We now fine-tune our pre-training network, i.e super-network with the following hyperparameters. We have to pass an additional argument to specify if our dataset is regression or not (determines the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters[\"per_device_train_batch_size\"] = 8\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 8\n",
    "hyperparameters[\"learning_rate\"] = 2e-05\n",
    "hyperparameters[\"num_train_epochs\"] = 5\n",
    "hyperparameters[\"save_strategy\"] = \"epoch\"\n",
    "hyperparameters[\n",
    "    \"is_regression\"\n",
    "] = False  # set this to True if your dataset is a regression dataset, for example STSB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the checkpoint of the model on S3, such that we can load it later in the second phase for the multi-objective search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.estimator:SMDebug Does Not Currently Support                         Distributed Training Jobs With Checkpointing Enabled\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-08-08-08-18-01-334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 08:18:02 Starting - Starting the training job...\n",
      "2023-08-08 08:18:16 Starting - Preparing the instances for training......\n",
      "2023-08-08 08:19:23 Downloading - Downloading input data......\n",
      "2023-08-08 08:20:18 Training - Downloading the training image...............\n",
      "2023-08-08 08:22:43 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-08-08 08:22:55,920 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-08-08 08:22:55,942 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-08 08:22:55,954 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:22:55,958 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:22:57,206 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/aaronkl/transformers.git (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mCloning https://github.com/aaronkl/transformers.git to /tmp/pip-req-build-lyf4k63q\u001b[0m\n",
      "\u001b[34mRunning command git clone --filter=blob:none --quiet https://github.com/aaronkl/transformers.git /tmp/pip-req-build-lyf4k63q\u001b[0m\n",
      "\u001b[34mResolved https://github.com/aaronkl/transformers.git to commit a40386669f2b4c147439bb4370cecd7b764ace8a\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.13.1+cu117)\u001b[0m\n",
      "\u001b[34mCollecting evaluate (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 5.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->-r requirements.txt (line 5)) (4.7.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0 (from evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for datasets>=2.0.0 from https://files.pythonhosted.org/packages/25/55/ec0d602cec473f3857ca82c9f2ddbd5b8c4d1139debbf06e19aaff29f973/datasets-2.14.3-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.3-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xxhash from https://files.pythonhosted.org/packages/45/63/40da996350689cf29db7f8819aafa74c9d36feca4f0e4393d220c619a1dc/xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub>=0.7.0 (from evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for huggingface-hub>=0.7.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (23.1)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19 (from evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0.dev0->-r requirements.txt (line 7)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0.dev0->-r requirements.txt (line 7)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.24.0.dev0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/5e/a8/2e3626392c4fcf7e3920cae166155542838be2048384989e2c6f024b793d/regex-2023.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 9.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.24.0.dev0->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 78.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 6)) (12.0.1)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/5b/8d/821fcb268cfc056964a75da3823896b17eabaa4968a2414121bc93b0c501/aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 6)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 6)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 6)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 6)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6)) (23.1.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 26.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.4/269.4 kB 52.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b5/03/7dec2e257bd173b5ca1f74477863b97d322149f6f0284d7decead8c5ceeb/frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.3-py3-none-any.whl (519 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.1/519.1 kB 68.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 49.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.9/769.9 kB 76.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.8/193.8 kB 37.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 82.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 40.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: transformers\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for transformers: filename=transformers-4.24.0.dev0-py3-none-any.whl size=5419859 sha256=9afe81daafe9a61c4474ffea6f20b0b78830b8e8386d4724a47584ed34243536\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-q6sw738z/wheels/20/07/29/0cc93aaae6b36fb6655bd9d0427bc9f8a3ba3108e06f5d30da\u001b[0m\n",
      "\u001b[34mSuccessfully built transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, xxhash, regex, multidict, frozenlist, async-timeout, yarl, responses, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.14.3 evaluate-0.4.0 frozenlist-1.4.0 huggingface-hub-0.16.4 multidict-6.0.4 regex-2023.6.3 responses-0.18.0 tokenizers-0.13.3 transformers-4.24.0.dev0 xxhash-3.3.0 yarl-1.9.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,163 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,163 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,212 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,255 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,299 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,317 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"is_regression\": false,\n",
      "        \"learning_rate\": 2e-05,\n",
      "        \"model_name_or_path\": \"bert-base-cased\",\n",
      "        \"num_train_epochs\": 5,\n",
      "        \"output_dir\": \"/opt/ml/checkpoints\",\n",
      "        \"per_device_eval_batch_size\": 8,\n",
      "        \"per_device_train_batch_size\": 8,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"seed\": 42,\n",
      "        \"task_name\": \"rte\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-08-08-08-18-01-334\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-770209394645/pytorch-training-2023-08-08-08-18-01-334/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"is_regression\":false,\"learning_rate\":2e-05,\"model_name_or_path\":\"bert-base-cased\",\"num_train_epochs\":5,\"output_dir\":\"/opt/ml/checkpoints\",\"per_device_eval_batch_size\":8,\"per_device_train_batch_size\":8,\"save_strategy\":\"epoch\",\"seed\":42,\"task_name\":\"rte\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-770209394645/pytorch-training-2023-08-08-08-18-01-334/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"is_regression\":false,\"learning_rate\":2e-05,\"model_name_or_path\":\"bert-base-cased\",\"num_train_epochs\":5,\"output_dir\":\"/opt/ml/checkpoints\",\"per_device_eval_batch_size\":8,\"per_device_train_batch_size\":8,\"save_strategy\":\"epoch\",\"seed\":42,\"task_name\":\"rte\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2023-08-08-08-18-01-334\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-770209394645/pytorch-training-2023-08-08-08-18-01-334/source/sourcedir.tar.gz\",\"module_name\":\"training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--is_regression\",\"False\",\"--learning_rate\",\"2e-05\",\"--model_name_or_path\",\"bert-base-cased\",\"--num_train_epochs\",\"5\",\"--output_dir\",\"/opt/ml/checkpoints\",\"--per_device_eval_batch_size\",\"8\",\"--per_device_train_batch_size\",\"8\",\"--save_strategy\",\"epoch\",\"--seed\",\"42\",\"--task_name\",\"rte\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_IS_REGRESSION=false\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=bert-base-cased\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=42\u001b[0m\n",
      "\u001b[34mSM_HP_TASK_NAME=rte\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 training.py --is_regression False --learning_rate 2e-05 --model_name_or_path bert-base-cased --num_train_epochs 5 --output_dir /opt/ml/checkpoints --per_device_eval_batch_size 8 --per_device_train_batch_size 8 --save_strategy epoch --seed 42 --task_name rte\u001b[0m\n",
      "\u001b[34m2023-08-08 08:23:18,349 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 4.38kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 92.4kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 1.51MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 1.51MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 42.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 100%|██████████| 28.8k/28.8k [00:00<00:00, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading metadata: 100%|██████████| 28.7k/28.7k [00:00<00:00, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 27.9k/27.9k [00:00<00:00, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/697k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 697k/697k [00:00<00:00, 25.8MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:   0%|          | 0/2490 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  92%|█████████▏| 2291/2490 [00:00<00:00, 22857.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100%|██████████| 2490/2490 [00:00<00:00, 22584.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating validation split:   0%|          | 0/277 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating validation split: 100%|██████████| 277/277 [00:00<00:00, 21719.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split:  89%|████████▉ | 2668/3000 [00:00<00:00, 26626.45 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split: 100%|██████████| 3000/3000 [00:00<00:00, 25470.61 examples/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 100%|██████████| 5.75k/5.75k [00:00<00:00, 4.76MB/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/2490 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 1000/2490 [00:00<00:00, 6879.63 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 2000/2490 [00:00<00:00, 6911.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 2490/2490 [00:00<00:00, 6801.49 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/277 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 277/277 [00:00<00:00, 6438.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 1000/3000 [00:00<00:00, 8362.15 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 2000/3000 [00:00<00:00, 8355.34 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 3000/3000 [00:00<00:00, 5611.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 3000/3000 [00:00<00:00, 6106.95 examples/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   5%|▍         | 21.0M/436M [00:00<00:02, 180MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  14%|█▍        | 62.9M/436M [00:00<00:01, 272MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  24%|██▍       | 105M/436M [00:00<00:01, 306MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  34%|███▎      | 147M/436M [00:00<00:00, 323MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  43%|████▎     | 189M/436M [00:00<00:00, 330MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  53%|█████▎    | 231M/436M [00:00<00:00, 336MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  63%|██████▎   | 273M/436M [00:00<00:00, 339MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  72%|███████▏  | 315M/436M [00:00<00:00, 339MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  82%|████████▏ | 357M/436M [00:01<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  91%|█████████▏| 398M/436M [00:01<00:00, 341MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin: 100%|██████████| 436M/436M [00:01<00:00, 337MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin: 100%|██████████| 436M/436M [00:01<00:00, 327MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m0%|          | 0/1090 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-08-08 08:23:29.815 algo-1:88 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-08-08 08:23:29.880 algo-1:88 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m0%|          | 1/1090 [00:02<44:33,  2.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1090 [00:02<23:42,  1.31s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1090 [00:03<16:31,  1.10it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1090 [00:03<13:23,  1.35it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1090 [00:04<11:05,  1.63it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 6/1090 [00:04<10:28,  1.73it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 7/1090 [00:05<10:06,  1.79it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1090 [00:05<09:22,  1.92it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1090 [00:06<08:40,  2.08it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1090 [00:06<08:52,  2.03it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1090 [00:07<08:37,  2.09it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1090 [00:07<08:12,  2.19it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1090 [00:07<08:09,  2.20it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 14/1090 [00:08<07:46,  2.31it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 15/1090 [00:08<07:30,  2.39it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 16/1090 [00:09<07:47,  2.30it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/1090 [00:09<07:41,  2.33it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 18/1090 [00:10<08:04,  2.21it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 19/1090 [00:10<07:51,  2.27it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/1090 [00:10<07:47,  2.29it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 21/1090 [00:11<07:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 22/1090 [00:11<08:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 23/1090 [00:12<07:53,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 24/1090 [00:12<07:52,  2.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1090 [00:13<07:29,  2.37it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1090 [00:13<07:47,  2.28it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 27/1090 [00:14<07:47,  2.27it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 28/1090 [00:14<07:43,  2.29it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 29/1090 [00:14<07:57,  2.22it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 30/1090 [00:15<07:45,  2.28it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 31/1090 [00:15<08:07,  2.17it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 32/1090 [00:16<08:27,  2.08it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 33/1090 [00:16<08:19,  2.12it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 34/1090 [00:17<08:09,  2.16it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 35/1090 [00:17<07:57,  2.21it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 36/1090 [00:18<08:04,  2.17it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 37/1090 [00:18<08:15,  2.12it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 38/1090 [00:19<08:07,  2.16it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 39/1090 [00:19<07:34,  2.31it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 40/1090 [00:19<07:49,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 41/1090 [00:20<07:35,  2.30it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 42/1090 [00:20<07:31,  2.32it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 43/1090 [00:21<07:38,  2.28it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 44/1090 [00:21<07:41,  2.27it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 45/1090 [00:22<07:41,  2.26it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 46/1090 [00:22<07:45,  2.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 47/1090 [00:23<07:43,  2.25it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 48/1090 [00:23<07:30,  2.31it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 49/1090 [00:23<07:24,  2.34it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 50/1090 [00:24<07:26,  2.33it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 51/1090 [00:24<07:53,  2.20it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 52/1090 [00:25<07:53,  2.19it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 53/1090 [00:25<08:07,  2.13it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 54/1090 [00:26<07:49,  2.21it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 55/1090 [00:26<07:35,  2.27it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 56/1090 [00:27<07:27,  2.31it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 57/1090 [00:27<07:28,  2.31it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 58/1090 [00:27<07:12,  2.39it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 59/1090 [00:28<07:20,  2.34it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 60/1090 [00:28<07:26,  2.31it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 61/1090 [00:29<07:29,  2.29it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 62/1090 [00:29<07:33,  2.27it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 63/1090 [00:30<07:22,  2.32it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 64/1090 [00:30<06:59,  2.44it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 65/1090 [00:30<06:50,  2.50it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 66/1090 [00:31<07:15,  2.35it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 67/1090 [00:31<07:39,  2.23it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 68/1090 [00:32<07:19,  2.32it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 69/1090 [00:32<07:07,  2.39it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 70/1090 [00:32<07:05,  2.40it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 71/1090 [00:33<07:16,  2.33it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 72/1090 [00:33<07:41,  2.21it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 73/1090 [00:34<07:42,  2.20it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 74/1090 [00:34<07:43,  2.19it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 75/1090 [00:35<07:40,  2.20it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 76/1090 [00:35<08:06,  2.08it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 77/1090 [00:36<07:50,  2.15it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 78/1090 [00:36<07:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 79/1090 [00:37<08:01,  2.10it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 80/1090 [00:37<07:51,  2.14it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 81/1090 [00:38<07:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 82/1090 [00:38<07:23,  2.27it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 83/1090 [00:38<07:06,  2.36it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 84/1090 [00:39<07:06,  2.36it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 85/1090 [00:39<07:24,  2.26it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 86/1090 [00:40<07:32,  2.22it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 87/1090 [00:40<07:27,  2.24it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 88/1090 [00:41<07:25,  2.25it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 89/1090 [00:41<07:19,  2.28it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 90/1090 [00:42<07:29,  2.22it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 91/1090 [00:42<07:35,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 92/1090 [00:42<07:16,  2.29it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 93/1090 [00:43<07:22,  2.25it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 94/1090 [00:43<07:03,  2.35it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 95/1090 [00:44<07:05,  2.34it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 96/1090 [00:44<07:37,  2.17it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 97/1090 [00:45<07:34,  2.18it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 98/1090 [00:45<07:37,  2.17it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 99/1090 [00:46<07:53,  2.09it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 100/1090 [00:46<07:47,  2.12it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 101/1090 [00:47<07:37,  2.16it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 102/1090 [00:47<07:23,  2.23it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 103/1090 [00:47<07:32,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 104/1090 [00:48<07:21,  2.23it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 105/1090 [00:48<07:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 106/1090 [00:49<07:17,  2.25it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 107/1090 [00:49<07:35,  2.16it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 108/1090 [00:50<07:41,  2.13it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 109/1090 [00:50<07:28,  2.19it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 110/1090 [00:51<07:31,  2.17it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 111/1090 [00:51<07:41,  2.12it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 112/1090 [00:52<07:26,  2.19it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 113/1090 [00:52<07:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 114/1090 [00:53<07:29,  2.17it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 115/1090 [00:53<07:24,  2.19it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 116/1090 [00:54<07:50,  2.07it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 117/1090 [00:54<07:59,  2.03it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 118/1090 [00:54<07:25,  2.18it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 119/1090 [00:55<07:24,  2.18it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 120/1090 [00:55<06:57,  2.32it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 121/1090 [00:56<07:14,  2.23it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 122/1090 [00:56<07:19,  2.20it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 123/1090 [00:57<07:03,  2.29it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 124/1090 [00:57<07:25,  2.17it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 125/1090 [00:58<07:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 126/1090 [00:58<07:17,  2.20it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 127/1090 [00:58<07:10,  2.24it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 128/1090 [00:59<07:10,  2.23it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 129/1090 [00:59<07:01,  2.28it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 130/1090 [01:00<07:25,  2.16it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 131/1090 [01:00<07:29,  2.13it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 132/1090 [01:01<07:33,  2.11it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 133/1090 [01:01<07:35,  2.10it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 134/1090 [01:02<07:14,  2.20it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 135/1090 [01:02<07:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 136/1090 [01:03<07:03,  2.25it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 137/1090 [01:03<06:45,  2.35it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 138/1090 [01:03<06:39,  2.39it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 139/1090 [01:04<06:45,  2.35it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 140/1090 [01:04<06:39,  2.38it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 141/1090 [01:05<06:42,  2.36it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 142/1090 [01:05<06:48,  2.32it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 143/1090 [01:06<06:56,  2.27it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 144/1090 [01:06<06:57,  2.26it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 145/1090 [01:06<06:43,  2.34it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 146/1090 [01:07<06:29,  2.42it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 147/1090 [01:07<06:53,  2.28it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 148/1090 [01:08<06:44,  2.33it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 149/1090 [01:08<06:54,  2.27it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 150/1090 [01:09<06:56,  2.26it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 151/1090 [01:09<07:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 152/1090 [01:09<06:48,  2.29it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 153/1090 [01:10<06:52,  2.27it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 154/1090 [01:10<07:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 155/1090 [01:11<07:15,  2.14it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 156/1090 [01:11<07:09,  2.17it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 157/1090 [01:12<07:12,  2.15it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 158/1090 [01:12<07:28,  2.08it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 159/1090 [01:13<07:36,  2.04it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 160/1090 [01:13<07:12,  2.15it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 161/1090 [01:14<06:52,  2.25it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 162/1090 [01:14<06:46,  2.28it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 163/1090 [01:15<06:53,  2.24it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 164/1090 [01:15<06:55,  2.23it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 165/1090 [01:15<07:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 166/1090 [01:16<07:00,  2.20it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 167/1090 [01:16<06:41,  2.30it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 168/1090 [01:17<07:00,  2.19it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 169/1090 [01:17<07:13,  2.12it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 170/1090 [01:18<07:05,  2.16it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 171/1090 [01:18<07:03,  2.17it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 172/1090 [01:19<07:00,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 173/1090 [01:19<07:19,  2.09it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 174/1090 [01:20<07:26,  2.05it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 175/1090 [01:20<07:21,  2.07it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 176/1090 [01:21<07:03,  2.16it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 177/1090 [01:21<06:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 178/1090 [01:22<07:05,  2.15it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 179/1090 [01:22<07:14,  2.10it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 180/1090 [01:22<07:06,  2.14it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 181/1090 [01:23<07:02,  2.15it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 182/1090 [01:23<07:06,  2.13it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 183/1090 [01:24<06:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 184/1090 [01:24<07:07,  2.12it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 185/1090 [01:25<07:13,  2.09it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 186/1090 [01:25<07:31,  2.00it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 187/1090 [01:26<07:23,  2.04it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 188/1090 [01:26<06:57,  2.16it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 189/1090 [01:27<07:09,  2.10it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 190/1090 [01:27<07:05,  2.11it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 191/1090 [01:28<07:13,  2.07it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 192/1090 [01:28<06:58,  2.14it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 193/1090 [01:29<07:14,  2.06it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 194/1090 [01:29<06:55,  2.16it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 195/1090 [01:30<07:04,  2.11it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 196/1090 [01:30<06:38,  2.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 197/1090 [01:30<06:58,  2.13it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 198/1090 [01:31<06:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 199/1090 [01:31<06:47,  2.19it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 200/1090 [01:32<07:01,  2.11it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 201/1090 [01:32<06:53,  2.15it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 202/1090 [01:33<06:28,  2.29it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 203/1090 [01:33<06:14,  2.37it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 204/1090 [01:34<06:28,  2.28it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 205/1090 [01:34<06:30,  2.26it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 206/1090 [01:34<06:26,  2.29it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 207/1090 [01:35<06:28,  2.27it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 208/1090 [01:35<06:21,  2.31it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 209/1090 [01:36<06:40,  2.20it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 210/1090 [01:36<06:32,  2.24it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 211/1090 [01:37<06:35,  2.22it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 212/1090 [01:37<06:42,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 213/1090 [01:38<06:48,  2.14it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 214/1090 [01:38<06:53,  2.12it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 215/1090 [01:39<07:05,  2.06it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 216/1090 [01:39<07:00,  2.08it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 217/1090 [01:40<06:47,  2.14it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 218/1090 [01:40<06:51,  2.12it/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:epoch 0: training loss = 0.026977146044373512, evaluation metrics = 0.6345381526104418, runtime = 104.59609794616699\u001b[0m\n",
      "\u001b[34mINFO:root:Store checkpoint in: /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mINFO:root:/opt/ml/checkpoints/model.tar.gz\u001b[0m\n",
      "\u001b[34m20%|██        | 219/1090 [02:08<2:08:40,  8.86s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 220/1090 [02:09<1:31:51,  6.33s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 221/1090 [02:09<1:06:20,  4.58s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 222/1090 [02:10<48:32,  3.36s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 223/1090 [02:10<36:00,  2.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 224/1090 [02:11<27:15,  1.89s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 225/1090 [02:11<20:55,  1.45s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 226/1090 [02:12<17:00,  1.18s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 227/1090 [02:12<13:53,  1.04it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 228/1090 [02:13<11:43,  1.23it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 229/1090 [02:13<10:13,  1.40it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 230/1090 [02:14<08:58,  1.60it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 231/1090 [02:14<08:32,  1.68it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 232/1090 [02:15<07:48,  1.83it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 233/1090 [02:15<07:07,  2.00it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 234/1090 [02:15<06:51,  2.08it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 235/1090 [02:16<06:51,  2.08it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 236/1090 [02:16<06:40,  2.13it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 237/1090 [02:17<06:48,  2.09it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 238/1090 [02:17<06:36,  2.15it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 239/1090 [02:18<06:33,  2.16it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 240/1090 [02:18<06:41,  2.12it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 241/1090 [02:19<06:41,  2.11it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 242/1090 [02:19<06:47,  2.08it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 243/1090 [02:20<06:38,  2.13it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 244/1090 [02:20<06:41,  2.11it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 245/1090 [02:21<06:19,  2.22it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 246/1090 [02:21<06:23,  2.20it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 247/1090 [02:21<06:12,  2.26it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 248/1090 [02:22<06:17,  2.23it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 249/1090 [02:22<06:39,  2.11it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 250/1090 [02:23<06:47,  2.06it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 251/1090 [02:23<06:35,  2.12it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 252/1090 [02:24<06:44,  2.07it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 253/1090 [02:24<06:36,  2.11it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 254/1090 [02:25<06:35,  2.11it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 255/1090 [02:25<06:38,  2.10it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 256/1090 [02:26<06:31,  2.13it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 257/1090 [02:26<06:25,  2.16it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 258/1090 [02:27<06:48,  2.04it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 259/1090 [02:27<06:28,  2.14it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 260/1090 [02:28<06:32,  2.11it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 261/1090 [02:28<06:40,  2.07it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 262/1090 [02:29<06:54,  2.00it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 263/1090 [02:29<06:43,  2.05it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 264/1090 [02:30<06:41,  2.06it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 265/1090 [02:30<06:42,  2.05it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 266/1090 [02:31<06:27,  2.12it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 267/1090 [02:31<06:28,  2.12it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 268/1090 [02:32<06:23,  2.15it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 269/1090 [02:32<06:22,  2.14it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 270/1090 [02:32<06:19,  2.16it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 271/1090 [02:33<06:21,  2.14it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 272/1090 [02:33<06:08,  2.22it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 273/1090 [02:34<06:17,  2.16it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 274/1090 [02:34<06:07,  2.22it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 275/1090 [02:35<06:21,  2.14it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 276/1090 [02:35<06:31,  2.08it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 277/1090 [02:36<06:28,  2.09it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 278/1090 [02:36<06:17,  2.15it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 279/1090 [02:37<06:18,  2.14it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 280/1090 [02:37<06:05,  2.22it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 281/1090 [02:37<06:03,  2.23it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 282/1090 [02:38<06:13,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 283/1090 [02:38<06:19,  2.12it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 284/1090 [02:39<06:24,  2.10it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 285/1090 [02:39<06:21,  2.11it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 286/1090 [02:40<06:19,  2.12it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 287/1090 [02:40<06:19,  2.12it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 288/1090 [02:41<06:07,  2.18it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 289/1090 [02:41<05:57,  2.24it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 290/1090 [02:42<06:13,  2.14it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 291/1090 [02:42<06:15,  2.13it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 292/1090 [02:43<06:15,  2.12it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 293/1090 [02:43<06:02,  2.20it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 294/1090 [02:44<06:17,  2.11it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 295/1090 [02:44<06:25,  2.06it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 296/1090 [02:45<06:36,  2.00it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 297/1090 [02:45<06:24,  2.06it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 298/1090 [02:46<06:12,  2.13it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 299/1090 [02:46<06:16,  2.10it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 300/1090 [02:46<06:10,  2.13it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 301/1090 [02:47<06:14,  2.11it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 302/1090 [02:47<06:11,  2.12it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 303/1090 [02:48<06:13,  2.11it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 304/1090 [02:48<05:55,  2.21it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 305/1090 [02:49<06:10,  2.12it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 306/1090 [02:49<06:14,  2.10it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 307/1090 [02:50<06:30,  2.00it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 308/1090 [02:50<06:35,  1.98it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 309/1090 [02:51<06:47,  1.92it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 310/1090 [02:51<06:46,  1.92it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 311/1090 [02:52<06:44,  1.93it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 312/1090 [02:52<06:15,  2.07it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 313/1090 [02:53<06:20,  2.04it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 314/1090 [02:53<05:58,  2.16it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 315/1090 [02:54<05:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 316/1090 [02:54<06:02,  2.14it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 317/1090 [02:55<06:24,  2.01it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 318/1090 [02:55<06:25,  2.00it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 319/1090 [02:56<06:20,  2.02it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 320/1090 [02:56<06:37,  1.94it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 321/1090 [02:57<06:29,  1.97it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 322/1090 [02:57<06:10,  2.07it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 323/1090 [02:58<06:25,  1.99it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 324/1090 [02:58<06:12,  2.05it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 325/1090 [02:59<05:54,  2.16it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 326/1090 [02:59<05:36,  2.27it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 327/1090 [03:00<05:39,  2.25it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 328/1090 [03:00<05:51,  2.17it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 329/1090 [03:01<06:14,  2.03it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 330/1090 [03:01<06:05,  2.08it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 331/1090 [03:01<05:44,  2.20it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 332/1090 [03:02<06:04,  2.08it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 333/1090 [03:02<05:50,  2.16it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 334/1090 [03:03<05:51,  2.15it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 335/1090 [03:03<06:01,  2.09it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 336/1090 [03:04<06:15,  2.01it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 337/1090 [03:04<06:16,  2.00it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 338/1090 [03:05<06:27,  1.94it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 339/1090 [03:05<06:19,  1.98it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 340/1090 [03:06<06:23,  1.96it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 341/1090 [03:07<06:39,  1.87it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 342/1090 [03:07<06:28,  1.93it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 343/1090 [03:08<06:16,  1.98it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 344/1090 [03:08<06:21,  1.95it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 345/1090 [03:08<06:04,  2.04it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 346/1090 [03:09<06:16,  1.98it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 347/1090 [03:09<06:01,  2.06it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 348/1090 [03:10<06:04,  2.04it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 349/1090 [03:11<06:16,  1.97it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 350/1090 [03:11<06:14,  1.98it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 351/1090 [03:11<06:06,  2.01it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 352/1090 [03:12<06:03,  2.03it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 353/1090 [03:12<05:58,  2.06it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 354/1090 [03:13<06:02,  2.03it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 355/1090 [03:13<06:02,  2.03it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 356/1090 [03:14<06:18,  1.94it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 357/1090 [03:15<06:15,  1.95it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 358/1090 [03:15<06:22,  1.92it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 359/1090 [03:16<06:31,  1.87it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 360/1090 [03:16<06:20,  1.92it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 361/1090 [03:17<06:25,  1.89it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 362/1090 [03:17<06:31,  1.86it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 363/1090 [03:18<06:21,  1.91it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 364/1090 [03:18<06:06,  1.98it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 365/1090 [03:19<05:50,  2.07it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 366/1090 [03:19<06:01,  2.00it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 367/1090 [03:20<05:46,  2.09it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 368/1090 [03:20<05:44,  2.10it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 369/1090 [03:21<05:51,  2.05it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 370/1090 [03:21<05:54,  2.03it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 371/1090 [03:22<05:54,  2.03it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 372/1090 [03:22<05:44,  2.08it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 373/1090 [03:23<05:47,  2.06it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 374/1090 [03:23<05:39,  2.11it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 375/1090 [03:23<05:46,  2.07it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 376/1090 [03:24<05:33,  2.14it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 377/1090 [03:24<05:51,  2.03it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 378/1090 [03:25<05:47,  2.05it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 379/1090 [03:25<05:47,  2.05it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 380/1090 [03:26<05:45,  2.05it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 381/1090 [03:26<05:53,  2.00it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 382/1090 [03:27<06:07,  1.93it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 383/1090 [03:27<06:05,  1.93it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 384/1090 [03:28<05:59,  1.97it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 385/1090 [03:28<05:40,  2.07it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 386/1090 [03:29<05:49,  2.01it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 387/1090 [03:29<05:33,  2.11it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 388/1090 [03:30<05:21,  2.19it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 389/1090 [03:30<05:23,  2.17it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 390/1090 [03:31<05:27,  2.13it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 391/1090 [03:31<05:31,  2.11it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 392/1090 [03:32<05:26,  2.14it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 393/1090 [03:32<05:48,  2.00it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 394/1090 [03:33<05:45,  2.01it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 395/1090 [03:33<05:35,  2.07it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 396/1090 [03:34<05:34,  2.08it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 397/1090 [03:34<05:42,  2.02it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 398/1090 [03:35<05:35,  2.06it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 399/1090 [03:35<05:36,  2.05it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 400/1090 [03:36<05:37,  2.05it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 401/1090 [03:36<05:24,  2.12it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 402/1090 [03:37<05:36,  2.05it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 403/1090 [03:37<05:22,  2.13it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 404/1090 [03:38<05:28,  2.09it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 405/1090 [03:38<05:37,  2.03it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 406/1090 [03:39<05:30,  2.07it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 407/1090 [03:39<05:24,  2.11it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 408/1090 [03:39<05:27,  2.08it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 409/1090 [03:40<05:39,  2.01it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 410/1090 [03:40<05:34,  2.03it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 411/1090 [03:41<05:34,  2.03it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 412/1090 [03:41<05:35,  2.02it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 413/1090 [03:42<05:40,  1.99it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 414/1090 [03:43<05:44,  1.96it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 415/1090 [03:43<05:37,  2.00it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 416/1090 [03:43<05:32,  2.03it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 417/1090 [03:44<05:20,  2.10it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 418/1090 [03:44<05:13,  2.15it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 419/1090 [03:45<05:33,  2.01it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 420/1090 [03:45<05:17,  2.11it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 421/1090 [03:46<05:28,  2.04it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 422/1090 [03:46<05:22,  2.07it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 423/1090 [03:47<05:17,  2.10it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 424/1090 [03:47<05:31,  2.01it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 425/1090 [03:48<05:27,  2.03it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 426/1090 [03:48<05:36,  1.97it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 427/1090 [03:49<05:24,  2.04it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 428/1090 [03:49<05:22,  2.05it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 429/1090 [03:50<05:14,  2.10it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 430/1090 [03:50<04:57,  2.22it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 431/1090 [03:51<04:48,  2.29it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 432/1090 [03:51<05:08,  2.13it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 433/1090 [03:52<05:05,  2.15it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 434/1090 [03:52<05:09,  2.12it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 435/1090 [03:52<05:05,  2.15it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 436/1090 [03:53<04:57,  2.20it/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:epoch 1: training loss = 0.14644014835357666, evaluation metrics = 0.6506024096385542, runtime = 237.7801752090454\u001b[0m\n",
      "\u001b[34mINFO:root:Store checkpoint in: /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mINFO:root:/opt/ml/checkpoints/model.tar.gz\u001b[0m\n",
      "\u001b[34m40%|████      | 437/1090 [04:24<1:44:08,  9.57s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 438/1090 [04:24<1:14:31,  6.86s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 439/1090 [04:25<53:27,  4.93s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 440/1090 [04:25<38:44,  3.58s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 441/1090 [04:26<28:40,  2.65s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 442/1090 [04:26<21:35,  2.00s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 443/1090 [04:27<16:42,  1.55s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 444/1090 [04:27<13:12,  1.23s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 445/1090 [04:28<10:57,  1.02s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 446/1090 [04:28<09:30,  1.13it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 447/1090 [04:29<08:05,  1.32it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 448/1090 [04:29<07:09,  1.49it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 449/1090 [04:30<06:38,  1.61it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 450/1090 [04:30<05:52,  1.81it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 451/1090 [04:30<05:40,  1.88it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 452/1090 [04:31<05:23,  1.97it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 453/1090 [04:31<05:14,  2.02it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 454/1090 [04:32<05:06,  2.08it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 455/1090 [04:32<05:10,  2.04it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 456/1090 [04:33<05:22,  1.97it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 457/1090 [04:33<05:16,  2.00it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 458/1090 [04:34<05:15,  2.00it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 459/1090 [04:34<04:59,  2.11it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 460/1090 [04:35<04:56,  2.13it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 461/1090 [04:35<04:47,  2.19it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 462/1090 [04:36<04:47,  2.19it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 463/1090 [04:36<04:53,  2.14it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 464/1090 [04:37<04:43,  2.21it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 465/1090 [04:37<05:05,  2.05it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 466/1090 [04:38<05:08,  2.02it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 467/1090 [04:38<05:13,  1.99it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 468/1090 [04:39<05:09,  2.01it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 469/1090 [04:39<05:15,  1.97it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 470/1090 [04:40<05:07,  2.01it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 471/1090 [04:40<05:08,  2.01it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 472/1090 [04:41<05:04,  2.03it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 473/1090 [04:41<04:53,  2.10it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 474/1090 [04:42<04:51,  2.12it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 475/1090 [04:42<04:55,  2.08it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 476/1090 [04:43<04:56,  2.07it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 477/1090 [04:43<05:05,  2.01it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 478/1090 [04:44<05:07,  1.99it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 479/1090 [04:44<05:02,  2.02it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 480/1090 [04:44<04:54,  2.07it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 481/1090 [04:45<04:41,  2.16it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 482/1090 [04:45<04:44,  2.14it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 483/1090 [04:46<04:50,  2.09it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 484/1090 [04:46<04:45,  2.12it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 485/1090 [04:47<04:57,  2.04it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 486/1090 [04:47<04:48,  2.09it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 487/1090 [04:48<04:47,  2.10it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 488/1090 [04:48<04:46,  2.10it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 489/1090 [04:49<04:45,  2.10it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 490/1090 [04:49<04:46,  2.09it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 491/1090 [04:50<04:40,  2.13it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 492/1090 [04:50<04:44,  2.10it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 493/1090 [04:51<04:47,  2.08it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 494/1090 [04:51<04:37,  2.14it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 495/1090 [04:52<04:47,  2.07it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 496/1090 [04:52<04:52,  2.03it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 497/1090 [04:53<05:00,  1.97it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 498/1090 [04:53<04:54,  2.01it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 499/1090 [04:54<04:52,  2.02it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 500/1090 [04:54<04:44,  2.08it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 501/1090 [04:55<04:43,  2.08it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 502/1090 [04:55<04:49,  2.03it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 503/1090 [04:56<04:55,  1.98it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 504/1090 [04:56<05:03,  1.93it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 505/1090 [04:57<05:00,  1.95it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 506/1090 [04:57<04:44,  2.05it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 507/1090 [04:58<04:53,  1.99it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 508/1090 [04:58<04:40,  2.07it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 509/1090 [04:59<04:43,  2.05it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 510/1090 [04:59<04:47,  2.01it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 511/1090 [05:00<04:42,  2.05it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 512/1090 [05:00<04:43,  2.04it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 513/1090 [05:01<04:58,  1.93it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 514/1090 [05:01<04:43,  2.03it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 515/1090 [05:02<04:40,  2.05it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 516/1090 [05:02<04:54,  1.95it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 517/1090 [05:03<04:45,  2.00it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 518/1090 [05:03<04:50,  1.97it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 519/1090 [05:04<04:43,  2.01it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 520/1090 [05:04<04:47,  1.98it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 521/1090 [05:05<04:42,  2.01it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 522/1090 [05:05<04:43,  2.00it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 523/1090 [05:06<04:39,  2.03it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 524/1090 [05:06<04:42,  2.01it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 525/1090 [05:07<04:33,  2.07it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 526/1090 [05:07<04:25,  2.12it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 527/1090 [05:07<04:28,  2.10it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 538/1090 [05:13<04:46,  1.92it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 539/1090 [05:13<04:33,  2.02it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 540/1090 [05:14<04:20,  2.11it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 541/1090 [05:14<04:14,  2.16it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 542/1090 [05:15<04:14,  2.16it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 543/1090 [05:15<04:14,  2.15it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 544/1090 [05:15<04:08,  2.20it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 545/1090 [05:16<04:23,  2.07it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 546/1090 [05:16<04:22,  2.07it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 547/1090 [05:17<04:29,  2.01it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 548/1090 [05:17<04:24,  2.05it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 549/1090 [05:18<04:27,  2.02it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 550/1090 [05:18<04:17,  2.10it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 551/1090 [05:19<04:18,  2.08it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 552/1090 [05:19<04:14,  2.12it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 553/1090 [05:20<04:18,  2.08it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 554/1090 [05:20<04:26,  2.01it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 555/1090 [05:21<04:20,  2.05it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 556/1090 [05:21<04:12,  2.12it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 557/1090 [05:22<04:08,  2.14it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 558/1090 [05:22<04:11,  2.12it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 559/1090 [05:23<04:15,  2.08it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 560/1090 [05:23<04:16,  2.07it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 561/1090 [05:24<04:08,  2.13it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 562/1090 [05:24<04:07,  2.13it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 563/1090 [05:25<04:02,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 564/1090 [05:25<04:02,  2.17it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 565/1090 [05:26<04:07,  2.12it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 566/1090 [05:26<04:13,  2.06it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 567/1090 [05:26<04:11,  2.08it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 568/1090 [05:27<04:17,  2.02it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 569/1090 [05:27<04:11,  2.07it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 570/1090 [05:28<03:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 571/1090 [05:28<03:53,  2.22it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 572/1090 [05:29<03:59,  2.16it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 573/1090 [05:29<04:12,  2.04it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 574/1090 [05:30<04:17,  2.00it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 575/1090 [05:30<04:19,  1.98it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 576/1090 [05:31<04:24,  1.94it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 577/1090 [05:31<04:20,  1.97it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 578/1090 [05:32<04:10,  2.05it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 579/1090 [05:32<04:12,  2.03it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 580/1090 [05:33<04:12,  2.02it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 581/1090 [05:33<04:11,  2.02it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 582/1090 [05:34<04:02,  2.09it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 583/1090 [05:34<04:03,  2.08it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 584/1090 [05:35<04:11,  2.01it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 585/1090 [05:35<04:13,  2.00it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 586/1090 [05:36<04:05,  2.05it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 587/1090 [05:36<04:05,  2.05it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 588/1090 [05:37<04:00,  2.08it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 589/1090 [05:37<04:07,  2.03it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 590/1090 [05:38<03:54,  2.13it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 591/1090 [05:38<03:55,  2.12it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 592/1090 [05:39<03:56,  2.10it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 593/1090 [05:39<04:10,  1.99it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 594/1090 [05:40<03:57,  2.09it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 595/1090 [05:40<03:58,  2.07it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 596/1090 [05:41<03:56,  2.09it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 597/1090 [05:41<03:54,  2.10it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 598/1090 [05:42<03:50,  2.13it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 599/1090 [05:42<04:01,  2.03it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 600/1090 [05:43<03:59,  2.05it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 601/1090 [05:43<04:04,  2.00it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 602/1090 [05:43<03:53,  2.09it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 603/1090 [05:44<04:01,  2.02it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 604/1090 [05:45<04:01,  2.01it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 605/1090 [05:45<03:49,  2.11it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 606/1090 [05:45<03:53,  2.07it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 607/1090 [05:46<03:56,  2.04it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 608/1090 [05:46<03:51,  2.09it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 609/1090 [05:47<03:55,  2.04it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 610/1090 [05:47<04:02,  1.98it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 611/1090 [05:48<04:07,  1.93it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 612/1090 [05:49<04:08,  1.93it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 613/1090 [05:49<03:55,  2.02it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 614/1090 [05:49<03:53,  2.04it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 615/1090 [05:50<03:47,  2.09it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 616/1090 [05:50<03:57,  1.99it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 617/1090 [05:51<03:45,  2.10it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 618/1090 [05:51<03:40,  2.14it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 619/1090 [05:52<03:52,  2.03it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 620/1090 [05:52<03:48,  2.06it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 621/1090 [05:53<03:40,  2.13it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 622/1090 [05:53<03:46,  2.06it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 623/1090 [05:54<03:46,  2.06it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 624/1090 [05:54<03:48,  2.04it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 625/1090 [05:55<03:56,  1.97it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 626/1090 [05:55<04:03,  1.91it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 627/1090 [05:56<03:45,  2.05it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 628/1090 [05:56<03:40,  2.10it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 629/1090 [05:57<03:39,  2.10it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 630/1090 [05:57<03:29,  2.19it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 631/1090 [05:58<03:39,  2.09it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 632/1090 [05:58<03:31,  2.17it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 633/1090 [05:59<03:31,  2.16it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 634/1090 [05:59<03:32,  2.14it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 635/1090 [06:00<03:37,  2.09it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 636/1090 [06:00<03:31,  2.15it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 637/1090 [06:00<03:35,  2.10it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 638/1090 [06:01<03:32,  2.13it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 639/1090 [06:01<03:21,  2.24it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 640/1090 [06:02<03:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 641/1090 [06:02<03:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 642/1090 [06:03<03:34,  2.09it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 643/1090 [06:03<03:33,  2.09it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 644/1090 [06:04<03:31,  2.11it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 645/1090 [06:04<03:32,  2.10it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 646/1090 [06:05<03:33,  2.08it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 647/1090 [06:05<03:30,  2.10it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 648/1090 [06:06<03:35,  2.05it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 649/1090 [06:06<03:30,  2.09it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 650/1090 [06:07<03:31,  2.08it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 651/1090 [06:07<03:26,  2.13it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 652/1090 [06:08<03:26,  2.12it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 653/1090 [06:08<03:33,  2.05it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 654/1090 [06:09<03:26,  2.11it/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:epoch 2: training loss = 0.3186977207660675, evaluation metrics = 0.6586345381526104, runtime = 373.21927881240845\u001b[0m\n",
      "\u001b[34mINFO:root:Store checkpoint in: /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mINFO:root:/opt/ml/checkpoints/model.tar.gz\u001b[0m\n",
      "\u001b[34m60%|██████    | 655/1090 [06:40<1:10:20,  9.70s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 656/1090 [06:40<50:01,  6.92s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 657/1090 [06:41<36:00,  4.99s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 658/1090 [06:41<26:08,  3.63s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 659/1090 [06:42<19:12,  2.67s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 660/1090 [06:42<14:18,  2.00s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 661/1090 [06:42<10:57,  1.53s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 662/1090 [06:43<08:36,  1.21s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 663/1090 [06:43<07:05,  1.00it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 664/1090 [06:44<06:00,  1.18it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 665/1090 [06:44<05:13,  1.36it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 666/1090 [06:45<04:47,  1.47it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 667/1090 [06:45<04:17,  1.64it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 668/1090 [06:46<04:00,  1.76it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 669/1090 [06:46<03:40,  1.91it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 670/1090 [06:47<03:43,  1.88it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 671/1090 [06:47<03:34,  1.96it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 672/1090 [06:48<03:20,  2.08it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 673/1090 [06:48<03:15,  2.13it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 674/1090 [06:49<03:11,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 675/1090 [06:49<03:08,  2.20it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 676/1090 [06:50<03:21,  2.06it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 677/1090 [06:50<03:25,  2.01it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 678/1090 [06:51<03:27,  1.98it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 679/1090 [06:51<03:22,  2.03it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 680/1090 [06:52<03:24,  2.00it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 681/1090 [06:52<03:19,  2.05it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 682/1090 [06:53<03:23,  2.01it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 683/1090 [06:53<03:14,  2.09it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 684/1090 [06:53<03:16,  2.06it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 685/1090 [06:54<03:13,  2.09it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 686/1090 [06:54<03:01,  2.22it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 687/1090 [06:55<03:05,  2.17it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 688/1090 [06:55<03:07,  2.15it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 689/1090 [06:56<03:16,  2.04it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 690/1090 [06:56<03:07,  2.13it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 691/1090 [06:57<03:06,  2.14it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 692/1090 [06:57<03:01,  2.19it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 693/1090 [06:58<02:56,  2.25it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 694/1090 [06:58<03:04,  2.15it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 695/1090 [06:59<03:04,  2.14it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1006/1090 [09:50<00:36,  2.28it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1007/1090 [09:50<00:35,  2.31it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1008/1090 [09:51<00:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1009/1090 [09:51<00:36,  2.23it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1010/1090 [09:52<00:36,  2.20it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1011/1090 [09:52<00:37,  2.11it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1012/1090 [09:53<00:37,  2.10it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1013/1090 [09:53<00:36,  2.12it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1014/1090 [09:54<00:35,  2.15it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1015/1090 [09:54<00:35,  2.12it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1016/1090 [09:54<00:34,  2.12it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1017/1090 [09:55<00:33,  2.20it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1018/1090 [09:55<00:32,  2.19it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1019/1090 [09:56<00:32,  2.19it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1020/1090 [09:56<00:30,  2.28it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1021/1090 [09:57<00:29,  2.31it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1022/1090 [09:57<00:29,  2.28it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1023/1090 [09:58<00:29,  2.28it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1024/1090 [09:58<00:27,  2.37it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1025/1090 [09:58<00:28,  2.30it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1026/1090 [09:59<00:28,  2.22it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1027/1090 [09:59<00:27,  2.29it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1028/1090 [10:00<00:26,  2.32it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1029/1090 [10:00<00:26,  2.31it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1030/1090 [10:01<00:26,  2.28it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1031/1090 [10:01<00:26,  2.20it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1032/1090 [10:01<00:25,  2.28it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1033/1090 [10:02<00:26,  2.15it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1034/1090 [10:03<00:27,  2.06it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1035/1090 [10:03<00:26,  2.09it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1036/1090 [10:03<00:25,  2.14it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1037/1090 [10:04<00:24,  2.14it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1038/1090 [10:04<00:23,  2.25it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1039/1090 [10:05<00:22,  2.26it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1040/1090 [10:05<00:22,  2.27it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1041/1090 [10:06<00:20,  2.40it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1042/1090 [10:06<00:20,  2.33it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1043/1090 [10:06<00:19,  2.37it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1044/1090 [10:07<00:19,  2.31it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1045/1090 [10:07<00:20,  2.21it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1046/1090 [10:08<00:19,  2.24it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1047/1090 [10:08<00:18,  2.37it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1048/1090 [10:09<00:18,  2.31it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1049/1090 [10:09<00:18,  2.27it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1050/1090 [10:09<00:17,  2.35it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1051/1090 [10:10<00:16,  2.31it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1052/1090 [10:10<00:15,  2.38it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1053/1090 [10:11<00:15,  2.38it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1054/1090 [10:11<00:15,  2.30it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1055/1090 [10:12<00:15,  2.27it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1056/1090 [10:12<00:15,  2.20it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1057/1090 [10:13<00:15,  2.18it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1058/1090 [10:13<00:14,  2.20it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1059/1090 [10:13<00:13,  2.22it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1060/1090 [10:14<00:13,  2.21it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1061/1090 [10:14<00:13,  2.15it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1062/1090 [10:15<00:12,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1063/1090 [10:15<00:12,  2.21it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1064/1090 [10:16<00:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1065/1090 [10:16<00:11,  2.21it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1066/1090 [10:17<00:10,  2.29it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1067/1090 [10:17<00:09,  2.32it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1068/1090 [10:17<00:09,  2.31it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1069/1090 [10:18<00:09,  2.20it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1070/1090 [10:18<00:08,  2.24it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1071/1090 [10:19<00:08,  2.16it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1072/1090 [10:19<00:08,  2.19it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1073/1090 [10:20<00:08,  2.10it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1074/1090 [10:20<00:07,  2.09it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1075/1090 [10:21<00:06,  2.15it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1076/1090 [10:21<00:06,  2.14it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1077/1090 [10:22<00:05,  2.21it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1078/1090 [10:22<00:05,  2.12it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1079/1090 [10:23<00:04,  2.26it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1080/1090 [10:23<00:04,  2.18it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1081/1090 [10:23<00:04,  2.19it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1082/1090 [10:24<00:03,  2.20it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1083/1090 [10:24<00:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1084/1090 [10:25<00:02,  2.13it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1085/1090 [10:25<00:02,  2.23it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1086/1090 [10:26<00:01,  2.11it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1087/1090 [10:26<00:01,  2.08it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1088/1090 [10:27<00:00,  2.11it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1089/1090 [10:27<00:00,  2.19it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1090/1090 [10:28<00:00,  2.31it/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:epoch 4: training loss = 0.5030755400657654, evaluation metrics = 0.6733601070950469, runtime = 631.920556306839\u001b[0m\n",
      "\u001b[34mINFO:root:Store checkpoint in: /opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mINFO:root:/opt/ml/checkpoints/model.tar.gz\u001b[0m\n",
      "\u001b[34m100%|██████████| 1090/1090 [10:56<00:00,  1.66it/s]\u001b[0m\n",
      "\u001b[34m2023-08-08 08:34:25,349 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:34:25,350 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-08 08:34:25,350 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-08-08 08:34:46 Uploading - Uploading generated training model\n",
      "2023-08-08 08:34:52 Completed - Training job completed\n",
      "Training seconds: 930\n",
      "Billable seconds: 930\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "s3_bucket = session.default_bucket()\n",
    "s3_bucket_prefix = \"nas_amt/model_checkpoint\"\n",
    "s3_path = f\"s3://{s3_bucket}/{s3_bucket_prefix}\"\n",
    "\n",
    "sm_args = dict(\n",
    "    entry_point=\"training.py\",\n",
    "    source_dir=os.path.abspath(\"\"),\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    instance_count=1,\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    transformers_version=\"4.26\",\n",
    "    max_run=3600 * 72,\n",
    "    role=get_execution_role(),\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    checkpoint_s3_uri=s3_path,\n",
    ")\n",
    "\n",
    "est = PyTorch(**sm_args)\n",
    "est.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-objective search for sub-networks\n",
    "\n",
    "After the fine-tuning process, we begin the multi-objective search by sampling random sub-networks using AMT. A sub-network is defined by its number of layers, heads, and units in the intermediate fully connected layers. To access a sub-network, we place a binary mask over the super-network and mask out all components (i.e., heads, units) that are not part of the sub-network. Note that, HuggingFace transformers needs the hidden size to be a multiple of the number of head. We cannot change the hidden size, and hence the number of heads has to be in [1, 3, 6, 12].\n",
    "\n",
    "In contrast to single-objective optimization, in the multi-objective setting, we typically do not have a single solution that simultaneously optimizes all objectives. Instead, we aim to collect a set of solutions that *dominate* all other solutions in at least one objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can start the multi-objective search through AMT. We sample a total of 100 random sub-networks (defined by the parameter `max_jobs`) and evaluate 10 networks simultaneously (defined by `max_parallel_jobs`). The code to load the model checkpoint and evaluate the sub-network is available in the `evaluate_subnetwork.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: nas-search-08-08-2023-08-43-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of sub-networks we will evaluate\n",
    "max_jobs = 100\n",
    "max_parallel_jobs = 10\n",
    "\n",
    "# Entry point script to load the super-network and evaluate a sub-network\n",
    "entry_point = \"evaluate_subnetwork.py\"\n",
    "\n",
    "# Command line arguments for the entry point script\n",
    "hyperparameters = {\"model_name_or_path\": model_type, \"output_dir\": \"./tmp\", \"task_name\": \"rte\"}\n",
    "\n",
    "# Define the metric we want to maximize\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"num-parameters\", \"Regex\": \"number of parameters: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation-performance\", \"Regex\": \"validation score: ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "# Define HuggingFace estimator\n",
    "estimator = HuggingFace(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=\"./\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",  # instance types for the SageMaker training jobs\n",
    "    instance_count=1,\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    transformers_version=\"4.26\",\n",
    "    max_run=3600 * 72,\n",
    "    role=get_execution_role(),\n",
    "    volume_size=125,\n",
    "    model_uri=s3_path,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "tuning_job_name = f\"nas-search-{current_time}\"\n",
    "\n",
    "# Search space to define sub-networks\n",
    "hyperparameter_ranges = {\n",
    "    \"num_layers\": IntegerParameter(0, 12),\n",
    "    # To meet HuggingFace constraints, we can only set the number of head to these values\n",
    "    \"num_heads\": CategoricalParameter([1, 3, 6, 12]),\n",
    "    \"num_units\": IntegerParameter(0, 3072),\n",
    "}\n",
    "\n",
    "# Define AMT Tuner object\n",
    "my_tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=\"validation-performance\",\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_jobs=max_jobs,\n",
    "    strategy=\"Random\",\n",
    "    random_seed=seed,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    ")\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "my_tuner.fit(job_name=tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize Results\n",
    "\n",
    "To visualize our results, we parse AMT's history to collect all configurations of sub-networks and the corresponding metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "history = my_tuner.analytics().dataframe()\n",
    "data = []\n",
    "configs = []\n",
    "for i, t in enumerate(my_tuner.analytics().training_job_summaries()):\n",
    "    jn = t[\"TrainingJobName\"]\n",
    "    df = sagemaker.analytics.TrainingJobAnalytics(jn).dataframe()\n",
    "\n",
    "    row = history[history[\"TrainingJobName\"] == jn]\n",
    "    config = {\n",
    "        \"num-heads\": int(row[\"num_heads\"].iloc[0].strip('\"')),\n",
    "        \"num-layers\": int(row[\"num_layers\"]),\n",
    "        \"num-units\": int(row[\"num_units\"]),\n",
    "    }\n",
    "    configs.append(config)\n",
    "\n",
    "    p = []\n",
    "    for j, metric in enumerate(metric_definitions):\n",
    "        metric_name = metric[\"Name\"]\n",
    "        if \"metric_name\" not in df.keys():\n",
    "            continue\n",
    "\n",
    "        if metric_name == \"validation-performance\":\n",
    "            y = 1 - float(df[df[\"metric_name\"] == metric_name][\"value\"])\n",
    "        else:\n",
    "            y = float(df[df[\"metric_name\"] == metric_name][\"value\"])\n",
    "        p.append(y)\n",
    "    if len(p) > 0:\n",
    "        data.append(p)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now visualize the Pareto set, which represents the optimal set of sub-networks that dominate all other sub-networks in at least one metric. This implies that when we move from one sub-network of the Pareto set to another, we must either sacrifice performance or model size but improve the other.\n",
    "\n",
    "Ultimately, the Pareto set provides us the flexibility to choose the sub-network that best suits our preferences. We can decide how much we want to reduce the size of our network and how much performance we are willing to sacrifice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from multi_objective import get_pareto_optimal\n",
    "\n",
    "idx = get_pareto_optimal(data)\n",
    "x = data[idx, 0]\n",
    "y = data[idx, 1]\n",
    "\n",
    "plt.scatter(\n",
    "    x, y, marker=\"o\", s=80, facecolors=\"none\", edgecolors=\"C0\", linewidth=2, label=\"Pareto front\"\n",
    ")\n",
    "plt.xlabel(\"number of parameters\")\n",
    "plt.ylabel(\"validation error\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(linewidth=\"1\", alpha=0.4, which=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Model\n",
    "\n",
    "Base on the Pareto front above, we can select the best model for our use case and deploy it on an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data='s3://sagemaker-us-west-2-770209394645/nas_amt/model_checkpoint/model.tar.gz',  # path to your trained SageMaker model\n",
    "   role=get_execution_role(),                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.26\",                           # Transformers version used\n",
    "   pytorch_version=\"1.13\",                                # PyTorch version used\n",
    "   py_version='py39',       \n",
    "   entry_point='inference.py',\n",
    "    source_dir=\"./\",\n",
    "    env={'SM_HPS' : json.dumps(configs[0])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-west-2-770209394645/nas_amt/model_checkpoint/model.tar.gz), script artifact (./), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-west-2-770209394645/huggingface-pytorch-inference-2023-08-08-09-54-42-747/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2023-08-08-09-55-22-090\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-inference-2023-08-08-09-55-22-714\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-inference-2023-08-08-09-55-22-714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------"
     ]
    }
   ],
   "source": [
    "# deploy model to SageMaker Inference\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "   \"inputs\": [('No Weapons of Mass Destruction Found in Iraq Yet', 'Weapons of Mass Destruction Found in Iraq.')]\n",
    "}\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are done we can delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
